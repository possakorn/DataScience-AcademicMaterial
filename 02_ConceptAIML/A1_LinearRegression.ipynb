{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "673183e1-4fc3-45a2-801e-a5e08e689c73",
   "metadata": {},
   "source": [
    "# In this assignment, you will implement linear regression with one variable.\n",
    "### 100 points total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "be52b2b2-8b28-4a9c-bbca-bd73e2895afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear all variables\n",
    "%reset_selective -f a\n",
    "#import \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import loadtxt\n",
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37671359-c7d1-42fb-af77-3d503c13f463",
   "metadata": {},
   "source": [
    "## Load data from data.csv file (5 Points)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "id": "0b6c91e8-0fd1-4155-9393-d585cb76387c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete the function below to load the data from data.csv. \n",
    "# Return [X,y] where X is the input and y is the target\n",
    "def load_data(file_name):\n",
    "    # write your code here\n",
    "    X, y = np.loadtxt(file_name, dtype='float,float', delimiter=',', usecols=(0, 1), unpack=True)\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "id": "a90b6a87-2263-422c-9cd2-50c292ac5701",
   "metadata": {},
   "outputs": [],
   "source": [
    "[X,y] = load_data(\"data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab414dd6-1962-4f8c-93bb-f45c17f726b5",
   "metadata": {},
   "source": [
    "### Visualise the data (5 Points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "3562a7a0-a6eb-43b7-88de-8dbc8a08eedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vis_data(X,y):\n",
    "    # write your code here\n",
    "    fig = plt.figure(figsize = (10,10))\n",
    "    plt.scatter(X,y)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "d91a90d7-3698-4731-bc70-0d79a8485bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_data(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9964ba-c880-46e1-a4d5-7b4038d6cefc",
   "metadata": {},
   "source": [
    "## Implement a loss function (10 Points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "id": "dbf0c964-f00a-4913-9118-e21f61a06b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_true --> the target values.\n",
    "# y_pred --> the predicted values\n",
    "def loss(y_true, y_pred):    \n",
    "    #Calculating loss.\n",
    "    diff = y_pred - y_true\n",
    "    loss = (1 / (2*len(y_pred))) * np.sum((diff)**2)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b86eb67-995c-46d7-b7c7-bb213ecf208a",
   "metadata": {},
   "source": [
    "## Test loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "id": "78c77fa3-7a80-4a60-834e-0e9b49b52494",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.5"
      ]
     },
     "execution_count": 405,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss(np.array([5,2]),np.array([10,3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75a6c2b-6780-493c-bd9c-8f19636a257c",
   "metadata": {},
   "source": [
    "## Implement a function to calculate gradients (20 Points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "id": "0bd31748-20f9-4816-a9ed-c95cc72650bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input:\n",
    "# X --> Input.\n",
    "# y_true --> target values.\n",
    "# y_pred --> predictions.\n",
    "#return:\n",
    "# dw --> the gradient with respect to the weights\n",
    "# db --> the gradient with respect to the bias.\n",
    "def gradients(X, y_true, y_pred):\n",
    "    # write your code here\n",
    "    # calcualte the gradient\n",
    "    dw = ( 1 / len(X) ) * np.dot(X.T, y_pred - y_true)\n",
    "    db = ( 1 / len(X) ) * np.sum(y_pred - y_true)\n",
    "    return dw, db"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2712311a-610b-4160-a73d-e6a2d7a70e3a",
   "metadata": {},
   "source": [
    "## Test gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "id": "d0f2a127-7097-4c32-9a9c-1de9dff54ec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dw = -1.9999999999999996 , db = -0.3999999999999999\n"
     ]
    }
   ],
   "source": [
    "dw,db = gradients(np.array([5]),np.array([1.5]),np.array([1.1]))\n",
    "print(f'dw = {dw} , db = {db}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c34eb1-3cc4-4640-ae8b-55907228e33c",
   "metadata": {},
   "source": [
    "## Write a function that uses your loss and gradients to train a LR model (25 Points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "id": "cc7bba28-791e-42af-b667-02170d9bc691",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X --> Input.\n",
    "# y --> true/target value.\n",
    "# add more arguments as you need\n",
    "def train(X, y, learning_rate=0.01, num_iterations=1000):\n",
    "    # write your code here\n",
    "    \n",
    "    # set the default parameter\n",
    "    w, b = 0, 0\n",
    "    dif_loss = np.Infinity # using for stop iterations\n",
    "    loss_func_cur = None\n",
    "    cost_history = []\n",
    "    \n",
    "    print(f\"Setting iterations: {num_iterations} and learning rate: {learning_rate}\")\n",
    "    \n",
    "    for i in range(num_iterations):\n",
    "        \n",
    "        # get y_prediction\n",
    "        y_pred = np.dot(X, w) + b\n",
    "        \n",
    "        # get loss\n",
    "        loss_func = loss(y, y_pred)\n",
    "        if loss_func_cur != None: \n",
    "            dif_loss = loss_func - loss_func_cur\n",
    "        loss_func_cur = loss_func\n",
    "        cost_history.append(loss_func_cur)\n",
    "        \n",
    "        # get Gradients\n",
    "        dw,db = gradients(X,y,y_pred)\n",
    "        \n",
    "        # updated w, b\n",
    "        w -= learning_rate * dw\n",
    "        b -= learning_rate * db\n",
    "        \n",
    "        # visual the output\n",
    "        if i%100 == 0:\n",
    "            print(f\"round {i}: {w,b} , loss = {loss_func}, diff loss = {dif_loss} \")\n",
    "        \n",
    "        # stop the iteration if results give the optimal likelihood\n",
    "        if abs(dif_loss) < 1e-6:\n",
    "            print(f\"The maximum iterative round {i}: {w,b} , loss = {loss_func}, diff loss = {dif_loss} \")\n",
    "            break\n",
    "    # returning weights, bias and losses(List)\n",
    "    return w, b, loss_func, cost_history, i, learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "id": "176f08bc-16fd-429c-906a-bd8a9432f1f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting iterations: 1000 and learning rate: 0.5\n",
      "round 0: (1.846086771454969, 4.200808417490454) , loss = 36.47935578592967, diff loss = inf \n",
      "round 100: (-4.747664068332094, 10.719994637527323) , loss = 0.12072162089099499, diff loss = -0.00022021120151288764 \n",
      "The maximum iterative round 179: (-4.988698254141816, 10.846755407273495) , loss = 0.11765032913298663, diff loss = -9.482975257546489e-07 \n"
     ]
    }
   ],
   "source": [
    "w, b, loss_func, cost_history, number_of_iterations, learning_rate  = train(X, y, 0.5,1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b148ec87-39db-454f-a8fb-7dfd560a7969",
   "metadata": {},
   "source": [
    "## Write a function to use your model to predict (15 Points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "id": "00dc8c6c-19b8-41d5-a0e0-7104d73c2c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, w, b):\n",
    "    # write your code here\n",
    "    y_pred = np.dot(X, w) + b\n",
    "    # Returning predictions.\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a9a8f2c-1ad6-48a5-bebb-cbe3dc7d977e",
   "metadata": {},
   "source": [
    "### Visualise your predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "id": "5dc77ce4-38f8-4b6f-baff-14ce4b793455",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Regression')"
      ]
     },
     "execution_count": 418,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(8,6))\n",
    "plt.plot(X, y, 'y.')\n",
    "plt.plot(X, predict(X, w, b), 'r.')\n",
    "plt.legend([\"Data\", \"Predictions\"])\n",
    "plt.xlabel('X - Input')\n",
    "plt.ylabel('y - target / true')\n",
    "plt.title('Regression')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0395d794-f9c2-4fa3-ab64-660c60245d0b",
   "metadata": {},
   "source": [
    "## Calculate the fit score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "id": "56b4c13b-8813-4f24-9f1e-8ae8b0197aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "id": "91bb8994-487e-4983-a042-90de96dab129",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(y_true, y_pred):\n",
    "    return np.sqrt(np.mean((y_pred - y_true)**2))\n",
    "\n",
    "y_true = y\n",
    "y_pred = predict(X, w, b)\n",
    "model_accuracy_score = r2_score(y_true, y_pred)\n",
    "model_RMSE_score = rmse(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2377b1a7-89ce-42b3-b0f4-de82980923c9",
   "metadata": {},
   "source": [
    "### Use scikit-learn to fit a linear regression model using the data from data,csv (20 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "id": "833711e0-7714-4639-ab03-bfbdc1f66ed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modeling with Scikit-learn - linear regression\n",
      " The training accuracy equal to 0.9007929514755091\n",
      " The training RMSE equal to 0    0.485051\n",
      "dtype: float64\n",
      " The paramter: w = [[-5.00562638]] and b = [10.85565797]\n",
      "--------------------------------------------\n",
      "Modeling with pratical implemented linear regression \n",
      "Setting iterations: 179 and learning rate: 0.5\n",
      " The training accuracy equal to 0.9007824958284781\n",
      " The training RMSE equal to 0.4850761672651886\n",
      " The paramter: w = -4.988698254141816 and b = 10.846755407273495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\possa\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3438: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# write your code here\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "df_x = pd.DataFrame(X)\n",
    "df_y = pd.DataFrame(y)\n",
    "\n",
    "reg = LinearRegression().fit(df_x, df_y)\n",
    "\n",
    "# Summary section to compare self-implemented and scikitlearn lib\n",
    "print(\"Modeling with Scikit-learn - linear regression\")\n",
    "print(f\" The training accuracy equal to {reg.score(df_x, df_y)}\")\n",
    "print(f\" The training RMSE equal to {rmse(df_y,reg.predict(df_x))}\")\n",
    "print(f\" The paramter: w = {reg.coef_} and b = {reg.intercept_}\")\n",
    "\n",
    "print(\"--------------------------------------------\")\n",
    "print(\"Modeling with pratical implemented linear regression \")\n",
    "print(f\"Setting iterations: {number_of_iterations} and learning rate: {learning_rate}\")\n",
    "print(f\" The training accuracy equal to {model_accuracy_score}\")\n",
    "print(f\" The training RMSE equal to {model_RMSE_score}\")\n",
    "print(f\" The paramter: w = {w} and b = {b}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "14bf1346ba63fd7edbf2cdccdace1f23ffa06e525f007bc76dd6fce80dd34f40"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
