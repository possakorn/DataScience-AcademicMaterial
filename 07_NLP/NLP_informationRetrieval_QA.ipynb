{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6730fecf",
   "metadata": {},
   "source": [
    "# Assignment 2 \n",
    "### \\<Possakorn> \\<a1873765>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df2aac6",
   "metadata": {},
   "source": [
    "## A. Tasks as specified for your team structure\n",
    "\n",
    "**One headings for each task.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c2799a",
   "metadata": {},
   "source": [
    "### Read and pre-process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "44270c68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/tytatee/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/tytatee/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/tytatee/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# library\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string\n",
    "import nltk\n",
    "import re\n",
    "import spacy\n",
    "from tqdm.auto import tqdm\n",
    "import sys\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# Ensure necessary NLTK data is downloaded\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "import logging\n",
    "logging.getLogger().setLevel(logging.WARNING)\n",
    "logging.getLogger('sentence_transformers').setLevel(logging.WARNING)\n",
    "logging.getLogger('fastcoref').setLevel(logging.WARNING)\n",
    "\n",
    "def display_df(df):\n",
    "\tdisplay(HTML(df.to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6040a799",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Show the sys info----- 3.10.13 (main, Aug 24 2023, 12:59:26) [Clang 15.0.0 (clang-1500.1.0.2.5)]\n",
      "-----Show the data summary-----\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 7 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   id       1000 non-null   int64 \n",
      " 1   author   994 non-null    object\n",
      " 2   date     1000 non-null   object\n",
      " 3   year     1000 non-null   object\n",
      " 4   month    1000 non-null   object\n",
      " 5   topic    1000 non-null   object\n",
      " 6   article  1000 non-null   object\n",
      "dtypes: int64(1), object(6)\n",
      "memory usage: 54.8+ KB\n",
      "None\n",
      "-----Show the topic distribution-----\n",
      "-----Show 5 dataset views-----\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>author</th>\n",
       "      <th>date</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>topic</th>\n",
       "      <th>article</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17307</td>\n",
       "      <td>Marlise Simons</td>\n",
       "      <td>1/01/2017</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>architecture</td>\n",
       "      <td>PARIS  ?   When the Islamic State was about to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17292</td>\n",
       "      <td>Andy Newman</td>\n",
       "      <td>31/12/2016</td>\n",
       "      <td>2016</td>\n",
       "      <td>12</td>\n",
       "      <td>art</td>\n",
       "      <td>Angels are everywhere in the Mu?iz family?s ap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17298</td>\n",
       "      <td>Emma G. Fitzsimmons</td>\n",
       "      <td>2/01/2017</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>business</td>\n",
       "      <td>Finally. The Second Avenue subway opened in Ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17311</td>\n",
       "      <td>Carl Hulse</td>\n",
       "      <td>3/01/2017</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>business</td>\n",
       "      <td>WASHINGTON  ?   It?s   or   time for Republica...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17339</td>\n",
       "      <td>Jim Rutenberg</td>\n",
       "      <td>5/01/2017</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>business</td>\n",
       "      <td>For Megyn Kelly, the shift from Fox News to NB...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id               author        date  year month         topic  \\\n",
       "0  17307       Marlise Simons   1/01/2017  2017     1  architecture   \n",
       "1  17292          Andy Newman  31/12/2016  2016    12           art   \n",
       "2  17298  Emma G. Fitzsimmons   2/01/2017  2017     1      business   \n",
       "3  17311           Carl Hulse   3/01/2017  2017     1      business   \n",
       "4  17339        Jim Rutenberg   5/01/2017  2017     1      business   \n",
       "\n",
       "                                             article  \n",
       "0  PARIS  ?   When the Islamic State was about to...  \n",
       "1  Angels are everywhere in the Mu?iz family?s ap...  \n",
       "2  Finally. The Second Avenue subway opened in Ne...  \n",
       "3  WASHINGTON  ?   It?s   or   time for Republica...  \n",
       "4  For Megyn Kelly, the shift from Fox News to NB...  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# identify basic information\n",
    "print(\"-----Show the sys info-----\", sys.version)\n",
    "\n",
    "# read csv\n",
    "df = pd.read_csv('news_dataset.csv', encoding='ISO-8859-1')\n",
    "\n",
    "# identify basic information\n",
    "print(\"-----Show the data summary-----\")\n",
    "print(df.info())\n",
    "\n",
    "# we will select only 3 topics with strata amount\n",
    "print(\"-----Show the topic distribution-----\")\n",
    "df[['topic','article']].groupby('topic').count()\n",
    "\n",
    "# we show 10 dataset views\n",
    "print(\"-----Show 5 dataset views-----\")\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f39f7ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentence = \"Megyn Kelly?s new office at NBC News sits a block north of Fox News headquarters in Midtown Manhattan. But it might as well be a world away. In switching networks at a pivotal point in her career, Ms. Kelly, the No.   personality in cable television news, is taking a calculated risk that she can swap her dedicated Fox audience for the broader, but more fickle, viewership of network television. There are challenges from the  . Her splashy arrival has the potential to fray nerves among the big personalities at the network  ?   who already compete against one another for interviews and scoops. Ms. Kelly, 46, will also be taking on a daytime talk show format that has been a virtual graveyard for television news personalities in the last 10 years. And the new Sunday newsmagazine show that NBC plans to build around Ms. Kelly will go up against a giant that has not been meaningfully challenged for decades: ?60 Minutes? on CBS. Still, Ms. Kelly is a bona fide star with a   book and a breakout role in this year?s presidential campaign, when she clashed with Donald J. Trump. NBC News comes out the winner in one of the most closely watched talent sweepstakes in years, acquiring one of television?s biggest names who could play a role in any number of major network events, like coverage of elections or the Olympics. Interviews on Tuesday with network executives and producers  ?   from Fox, NBC and other rival channels  ?   suggest that Ms. Kelly?s performance at NBC will be as closely watched in the industry as her past few months of contract negotiations. Ms. Kelly will have to design her daytime talk show from scratch. Even though she made her name as a news anchor, she has argued that she is not obsessed with politics. When she hosted a   special on Fox in May  ?   her first major foray outside cable news  ?   she expressed a desire to combine the qualities of Oprah Winfrey, Barbara Walters and Charlie Rose. That special  ?   which featured interviews with Mr. Trump, the celebrity lawyer Robert Shapiro and the actress Laverne Cox  ?   received middling reviews. It was far from a ratings hit: Among adults younger than 50, the demographic most important to broadcasters, Ms. Kelly?s special performed about as well as ABC?s ?Beyond the Tank,? a   spinoff. A daily daytime talk show also poses risks.   talent like Jane Pauley, Meredith Vieira, Katie Couric and Anderson Cooper have taken a stab at the genre in the past, and each one failed. In Ms. Pauley?s case, NBC invested millions of dollars, but the show was yanked in 2005 after just one year. NBC said on Tuesday that Ms. Kelly?s show was expected to be closer to a news program than the typical daytime talk show, although it is unclear what exactly that will mean or how much appetite there is for news amid a landscape including shows like ?Days of Our Lives,? ?The Ellen DeGeneres Show? and ?Steve Harvey. ? The audience for daytime television is also significantly more diverse than Fox?s   viewership. Starting a Sunday rival to ?60 Minutes,? the   among newsmagazines, is likewise no easy task. ?Rock Center,? which Brian Williams hosted, lasted two seasons. NBC?s most recent newsmagazine, ?On Assignment,? ran    against ?60 Minutes? over five weeks the show averaged about four million viewers, compared with more than nine million for ?60 Minutes,? which broadcast two repeats during that time. (This season, ?60 Minutes? is averaging more than 14 million viewers.) It is also unclear how NBC will accommodate Ms. Kelly?s show during the National Football League season, when NBC?s popular ?Sunday Night Football? package includes a highly rated pregame show that begins at 7 p. m. Eastern. But Andrew Lack, NBC News?s chairman, has long had newsmagazines in his blood. In addition to overseeing a ?60 Minutes? competitor on CBS in the 1980s, Mr. Lack presided over NBC in the 1990s when newsmagazines, including the network?s popular ?Dateline,? dominated   lineups. Fox, meanwhile, must now set a course without one of its biggest names, as the network continues to recalibrate itself after the ouster of its chairman, Roger Ailes. Ms. Kelly?s exit from Fox News was so abrupt that it was announced on the day that the network had run a   ad in The Wall Street Journal trumpeting the ratings of its   lineup, with Ms. Kelly prominently pictured. Her departure stunned the Fox newsroom, where journalists and executives spent Tuesday afternoon speculating over which anchor might replace Ms. Kelly in the coveted 9 p. m. slot  ?   and wondering if Ms. Kelly would even appear that night. When Greta Van Susteren, another veteran anchor, announced her departure in September, network representatives visited her home to tell her not to bother coming in. In the end, Ms. Kelly was granted a chance to bid farewell to Fox News viewers  ?   her last show is Friday. It is not clear who will replace her. Fox News has never had an     lineup. Potential replacements being floated inside the network on Tuesday include four women who have regularly filled in for Ms. Kelly: Sandra Smith, a host of Fox?s noon show, ?Outnumbered? Trish Regan, a rising star at Fox Business Network Shannon Bream, who covers the Supreme Court and Martha MacCallum, a morning anchor. Kimberly Guilfoyle, a host of ?The Five? who is friendly with Mr. Trump?s circle, and Tucker Carlson, who has put up high ratings since taking over Fox News?s 7 p. m. slot, have also been suggested. Sean Hannity, whose viewership at 10 p. m. increased enormously in 2016 and has spiked since Election Day, could be moved up an hour, but his momentum in his time slot may make Fox executives reluctant to make a switch. One winner in the sweepstakes for Ms. Kelly could be CNN, even though it did not succeed in recruiting her. CNN, while still behind Fox News in total viewers by a wide margin, has occasionally beaten Fox among viewers 25 to 54, the demographic that determines advertising rates. In 2016, CNN finished within 58, 000 viewers of Fox in prime time in the demographic  ?   cutting Fox?s lead in half. Since the election, Fox has regained a sizable lead, but now, without spending a penny, CNN will now have an opportunity to take another run at Fox?s   advantage.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "4e5e03e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'article_id': 17340,\n",
       "  'info': {'gold_sentence': 'Megyn Kelly?s new office at NBC News sits a block north of Fox News headquarters in Midtown Manhattan.',\n",
       "   'QA': [{'question': ['Where Megyn Kelly?s new office?'],\n",
       "     'gold_standard': ['Midtown Manhattan']},\n",
       "    {'question': ['Where Megyn Kelly?s new office?'],\n",
       "     'gold_standard': ['Midtown Manhattan']}]}}]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data = [\n",
    "#     {\n",
    "#         \"article_id\": article_id,\n",
    "#         \"question\": question,\n",
    "#         \"gold_sentence\": gold_sentence,\n",
    "#         \"gold_standard\": gold_standard\n",
    "#     } \n",
    "# ]\n",
    "data = [\n",
    "    {\n",
    "        \"article_id\": 17340,\n",
    "        \"info\": {\n",
    "            \"gold_sentence\" : \"Megyn Kelly?s new office at NBC News sits a block north of Fox News headquarters in Midtown Manhattan.\",\n",
    "            \"QA\": [\n",
    "                {\"question\": ['Where Megyn Kelly?s new office?'],\"gold_standard\": ['Midtown Manhattan']},\n",
    "                {\"question\": ['Where Megyn Kelly?s new office?'],\"gold_standard\": ['Midtown Manhattan']}\n",
    "\t\t\t]\n",
    "\t\t\t}\n",
    "\t\t} \n",
    "\t]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "37594bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read csv\n",
    "df_qk = pd.read_csv('sampling_data_quick.csv')\n",
    "df = pd.read_csv('news_dataset.csv', encoding='ISO-8859-1')\n",
    "df_sam = df[df['topic'].isin(['politics', 'business','entertainment'])].groupby('topic').sample(n=34, random_state=1311)\n",
    "df_sam = df_sam.reset_index(drop = True)\n",
    "df_sam.set_index('id', inplace=True)\n",
    "df_sam.head(5)\n",
    "df_dev = pd.read_csv('sampling_data_dev.csv')\n",
    "df_dev = pd.merge(df_dev, df[['id','article','topic']], on='id', how='inner')\n",
    "df_dev = df_dev.reset_index(drop = True)\n",
    "df_dev.set_index('id', inplace=True)\n",
    "df_dev\n",
    "df = df.reset_index(drop = True)\n",
    "df.set_index('id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "4ad4a876",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check the function preprocess\n",
      "Before: Megyn Kelly?s new office at NBC News sits a block north of Fox News headquarters in Midtown Manhattan. But it might as well be a world away. In switching networks at a pivotal point in her career, Ms. Kelly, the No.   personality in cable television news, is taking a calculated risk that she can swap her dedicated Fox audience for the broader, but more fickle, viewership of network television. There are challenges from the  . Her splashy arrival has the potential to fray nerves among the big personalities at the network  ?   who already compete against one another for interviews and scoops. Ms. Kelly, 46, will also be taking on a daytime talk show format that has been a virtual graveyard for television news personalities in the last 10 years. And the new Sunday newsmagazine show that NBC plans to build around Ms. Kelly will go up against a giant that has not been meaningfully challenged for decades: ?60 Minutes? on CBS. Still, Ms. Kelly is a bona fide star with a   book and a breakout role in this year?s presidential campaign, when she clashed with Donald J. Trump. NBC News comes out the winner in one of the most closely watched talent sweepstakes in years, acquiring one of television?s biggest names who could play a role in any number of major network events, like coverage of elections or the Olympics. Interviews on Tuesday with network executives and producers  ?   from Fox, NBC and other rival channels  ?   suggest that Ms. Kelly?s performance at NBC will be as closely watched in the industry as her past few months of contract negotiations. Ms. Kelly will have to design her daytime talk show from scratch. Even though she made her name as a news anchor, she has argued that she is not obsessed with politics. When she hosted a   special on Fox in May  ?   her first major foray outside cable news  ?   she expressed a desire to combine the qualities of Oprah Winfrey, Barbara Walters and Charlie Rose. That special  ?   which featured interviews with Mr. Trump, the celebrity lawyer Robert Shapiro and the actress Laverne Cox  ?   received middling reviews. It was far from a ratings hit: Among adults younger than 50, the demographic most important to broadcasters, Ms. Kelly?s special performed about as well as ABC?s ?Beyond the Tank,? a   spinoff. A daily daytime talk show also poses risks.   talent like Jane Pauley, Meredith Vieira, Katie Couric and Anderson Cooper have taken a stab at the genre in the past, and each one failed. In Ms. Pauley?s case, NBC invested millions of dollars, but the show was yanked in 2005 after just one year. NBC said on Tuesday that Ms. Kelly?s show was expected to be closer to a news program than the typical daytime talk show, although it is unclear what exactly that will mean or how much appetite there is for news amid a landscape including shows like ?Days of Our Lives,? ?The Ellen DeGeneres Show? and ?Steve Harvey. ? The audience for daytime television is also significantly more diverse than Fox?s   viewership. Starting a Sunday rival to ?60 Minutes,? the   among newsmagazines, is likewise no easy task. ?Rock Center,? which Brian Williams hosted, lasted two seasons. NBC?s most recent newsmagazine, ?On Assignment,? ran    against ?60 Minutes? over five weeks the show averaged about four million viewers, compared with more than nine million for ?60 Minutes,? which broadcast two repeats during that time. (This season, ?60 Minutes? is averaging more than 14 million viewers.) It is also unclear how NBC will accommodate Ms. Kelly?s show during the National Football League season, when NBC?s popular ?Sunday Night Football? package includes a highly rated pregame show that begins at 7 p. m. Eastern. But Andrew Lack, NBC News?s chairman, has long had newsmagazines in his blood. In addition to overseeing a ?60 Minutes? competitor on CBS in the 1980s, Mr. Lack presided over NBC in the 1990s when newsmagazines, including the network?s popular ?Dateline,? dominated   lineups. Fox, meanwhile, must now set a course without one of its biggest names, as the network continues to recalibrate itself after the ouster of its chairman, Roger Ailes. Ms. Kelly?s exit from Fox News was so abrupt that it was announced on the day that the network had run a   ad in The Wall Street Journal trumpeting the ratings of its   lineup, with Ms. Kelly prominently pictured. Her departure stunned the Fox newsroom, where journalists and executives spent Tuesday afternoon speculating over which anchor might replace Ms. Kelly in the coveted 9 p. m. slot  ?   and wondering if Ms. Kelly would even appear that night. When Greta Van Susteren, another veteran anchor, announced her departure in September, network representatives visited her home to tell her not to bother coming in. In the end, Ms. Kelly was granted a chance to bid farewell to Fox News viewers  ?   her last show is Friday. It is not clear who will replace her. Fox News has never had an     lineup. Potential replacements being floated inside the network on Tuesday include four women who have regularly filled in for Ms. Kelly: Sandra Smith, a host of Fox?s noon show, ?Outnumbered? Trish Regan, a rising star at Fox Business Network Shannon Bream, who covers the Supreme Court and Martha MacCallum, a morning anchor. Kimberly Guilfoyle, a host of ?The Five? who is friendly with Mr. Trump?s circle, and Tucker Carlson, who has put up high ratings since taking over Fox News?s 7 p. m. slot, have also been suggested. Sean Hannity, whose viewership at 10 p. m. increased enormously in 2016 and has spiked since Election Day, could be moved up an hour, but his momentum in his time slot may make Fox executives reluctant to make a switch. One winner in the sweepstakes for Ms. Kelly could be CNN, even though it did not succeed in recruiting her. CNN, while still behind Fox News in total viewers by a wide margin, has occasionally beaten Fox among viewers 25 to 54, the demographic that determines advertising rates. In 2016, CNN finished within 58, 000 viewers of Fox in prime time in the demographic  ?   cutting Fox?s lead in half. Since the election, Fox has regained a sizable lead, but now, without spending a penny, CNN will now have an opportunity to take another run at Fox?s   advantage.\n",
      "After: megyn kelly new office nbc news sits block north fox news headquarters midtown manhattan . might well world away . switching network pivotal point career ms. kelly . personality cable television news taking calculated risk swap dedicated fox audience broader fickle viewership network television . challenge . splashy arrival potential fray nerve among big personality network already compete one another interview scoop . ms. kelly 46 also taking daytime talk show format virtual graveyard television news personality last 10 year . new sunday newsmagazine show nbc plan build around ms. kelly go giant meaningfully challenged decade 60 minute cbs . still ms. kelly bona fide star book breakout role year presidential campaign clashed donald j. trump . nbc news come winner one closely watched talent sweepstakes year acquiring one television biggest name could play role number major network event like coverage election olympics . interview tuesday network executive producer fox nbc rival channel suggest ms. kelly performance nbc closely watched industry past month contract negotiation . ms. kelly design daytime talk show scratch . even though made name news anchor argued obsessed politics . hosted special fox may first major foray outside cable news expressed desire combine quality oprah winfrey barbara walter charlie rose . special featured interview mr. trump celebrity lawyer robert shapiro actress laverne cox received middling review . far rating hit among adult younger 50 demographic important broadcaster ms. kelly special performed well abc beyond tank spinoff . daily daytime talk show also pose risk . talent like jane pauley meredith vieira katie couric anderson cooper taken stab genre past one failed . ms. pauley case nbc invested million dollar show yanked 2005 one year . nbc said tuesday ms. kelly show expected closer news program typical daytime talk show although unclear exactly mean much appetite news amid landscape including show like day life ellen degeneres show steve harvey . audience daytime television also significantly diverse fox viewership . starting sunday rival 60 minute among newsmagazines likewise easy task . rock center brian williams hosted lasted two season . nbc recent newsmagazine assignment ran 60 minute five week show averaged four million viewer compared nine million 60 minute broadcast two repeat time . season 60 minute averaging 14 million viewer . also unclear nbc accommodate ms. kelly show national football league season nbc popular sunday night football package includes highly rated pregame show begin 7 p. m. eastern . andrew lack nbc news chairman long newsmagazines blood . addition overseeing 60 minute competitor cbs 1980s mr. lack presided nbc 1990s newsmagazines including network popular dateline dominated lineup . fox meanwhile must set course without one biggest name network continues recalibrate ouster chairman roger ailes . ms. kelly exit fox news abrupt announced day network run ad wall street journal trumpeting rating lineup ms. kelly prominently pictured . departure stunned fox newsroom journalist executive spent tuesday afternoon speculating anchor might replace ms. kelly coveted 9 p. m. slot wondering ms. kelly would even appear night . greta van susteren another veteran anchor announced departure september network representative visited home tell bother coming . end ms. kelly granted chance bid farewell fox news viewer last show friday . clear replace . fox news never lineup . potential replacement floated inside network tuesday include four woman regularly filled ms. kelly sandra smith host fox noon show outnumbered trish regan rising star fox business network shannon bream cover supreme court martha maccallum morning anchor . kimberly guilfoyle host five friendly mr. trump circle tucker carlson put high rating since taking fox news 7 p. m. slot also suggested . sean hannity whose viewership 10 p. m. increased enormously 2016 spiked since election day could moved hour momentum time slot may make fox executive reluctant make switch . one winner sweepstakes ms. kelly could cnn even though succeed recruiting . cnn still behind fox news total viewer wide margin occasionally beaten fox among viewer 25 54 demographic determines advertising rate . 2016 cnn finished within 58 000 viewer fox prime time demographic cutting fox lead half . since election fox regained sizable lead without spending penny cnn opportunity take another run fox advantage .\n"
     ]
    }
   ],
   "source": [
    "def preprocess_text(text, c_stop = True, c_lower = True, c_lemma = True):\n",
    "\t\n",
    "\t# 00 setting\n",
    "\n",
    "\tlemmatizer = WordNetLemmatizer()\n",
    "\tstop_words = set(stopwords.words('english'))\n",
    "\tif c_stop == False:\n",
    "\t\tstop_words = {}\n",
    "\t\n",
    "\t# 01 Lowercasing the text\n",
    "\t\n",
    "\tif c_lower == True:\n",
    "\t\ttext = text.lower()\n",
    "\t\n",
    "\t# Tokenizing while keeping punctuation\"\n",
    "\n",
    "\twords = word_tokenize(text)\n",
    " \n",
    "\t# 02 Lemmatization and stopping words removal; keeping \".\"\n",
    "\n",
    "\tif c_lemma == True:\n",
    "\t\tfiltered_words = [lemmatizer.lemmatize(word) for word in words \n",
    "\t\t\t\t\tif word not in stop_words \n",
    "\t\t\t\t\tand (word not in string.punctuation or word == '.')]\n",
    "\telse:\n",
    "\t\tfiltered_words = [word for word in words \n",
    "\t\t\t\t\tif word not in stop_words \n",
    "\t\t\t\t\tand (word not in string.punctuation or word == '.')]\n",
    "\t\n",
    "\t# Joining the processed words back into a string, preserving punctuation\n",
    "\n",
    "\treturn \" \".join(filtered_words)\n",
    "\n",
    "print(\"Check the function preprocess\")\n",
    "print(f\"Before: {test_sentence}\")\n",
    "print(f\"After: {preprocess_text(test_sentence)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e8c290d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Let?s just be very clear about this: There is no movie called ?Hidden Fences',\n",
       " '? But you would be forgiven for thinking otherwise after watching the Golden Globes, after the nonexistent movie was mentioned twice',\n",
       " 'The first time was definitely a mistake',\n",
       " 'The second time is not so clear',\n",
       " 'First, NBC?s Jenna Bush Hager, taking her first turn at Golden Globes reporting, presumably meant to ask Pharrell Williams about his best original score nomination for ?Hidden Figures,? a movie about three black women who would play crucial roles in the American space program',\n",
       " 'Surely she didn?t mean to ask him about ?Fences,? a similarly renowned film starring Viola Davis and Denzel Washington',\n",
       " 'Mr',\n",
       " 'Williams had no involvement in that',\n",
       " 'But: Mr',\n",
       " 'Williams?s   reaction, in which he appeared to be doing his best to hold back whatever he badly wished to say, was impressive in its restraint',\n",
       " 'Unsurprisingly, the immediate reaction on Twitter was less restrained',\n",
       " '?So Jenna Bush is just merging all of the black movies tonight at the #GoldenGlobes, huh?? one user asked',\n",
       " '?Pharrell?s face just held hundreds of years of whitewashing resolve,? another said',\n",
       " 'Others had fun in similarly inventing new movie titles',\n",
       " 'That seemed to be the end of things, but for some reason, Michael Keaton also referred to ?Hidden Fences? when listing the nominees for best supporting actress in a motion picture',\n",
       " 'Since the camera was focused on the actresses, it?s unclear if Mr',\n",
       " 'Keaton said it with a wink and a nod',\n",
       " '']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://www.geeksforgeeks.org/python-tokenize-text-using-textblob/\n",
    "import spacy\n",
    "from textblob import TextBlob\n",
    "\n",
    "def sentence_split(text, split_type='spacy'):\n",
    "\t# Use the SpaCy model for sentence tokenization\n",
    "\tif split_type == 'spacy':\n",
    "\t\t# Load the SpaCy model\n",
    "\t\tnlp = spacy.load('en_core_web_sm')\n",
    "\t\tdoc = nlp(text)\n",
    "\t\tsentences = [sent.text.strip() for sent in doc.sents]\n",
    "\t\treturn sentences\n",
    "\n",
    "\t# Use the Textblob model for sentence tokenization\n",
    "\telif split_type == 'textblob':\n",
    "\t\tblob_object = TextBlob(text)\n",
    "\t\treturn [(str(i)) for i in blob_object.sentences]\n",
    "\n",
    "\telif split_type == 'common':\n",
    "\t\treturn [text.strip() for text in text.split('.') if text]\n",
    "\n",
    "text =  \"\"\"\n",
    "Let?s just be very clear about this: There is no movie called ?Hidden Fences. ? But you would be forgiven for thinking otherwise after watching the Golden Globes, after the nonexistent movie was mentioned twice. The first time was definitely a mistake. The second time is not so clear. First, NBC?s Jenna Bush Hager, taking her first turn at Golden Globes reporting, presumably meant to ask Pharrell Williams about his best original score nomination for ?Hidden Figures,? a movie about three black women who would play crucial roles in the American space program. Surely she didn?t mean to ask him about ?Fences,? a similarly renowned film starring Viola Davis and Denzel Washington. Mr. Williams had no involvement in that. But: Mr. Williams?s   reaction, in which he appeared to be doing his best to hold back whatever he badly wished to say, was impressive in its restraint. Unsurprisingly, the immediate reaction on Twitter was less restrained. ?So Jenna Bush is just merging all of the black movies tonight at the #GoldenGlobes, huh?? one user asked. ?Pharrell?s face just held hundreds of years of whitewashing resolve,? another said. Others had fun in similarly inventing new movie titles. That seemed to be the end of things, but for some reason, Michael Keaton also referred to ?Hidden Fences? when listing the nominees for best supporting actress in a motion picture. Since the camera was focused on the actresses, it?s unclear if Mr. Keaton said it with a wink and a nod.\n",
    "\"\"\"\n",
    "\n",
    "context = sentence_split(text, 'common')\n",
    "# context = coreference_resolution(context)\n",
    "print(len(context))\n",
    "context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3505e219",
   "metadata": {},
   "source": [
    "### Coreference Resolution utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e8d5a600",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 34.82 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check the function coreference\n",
      "Before: Megyn Kelly?s new office at NBC News sits a block north of Fox News headquarters in Midtown Manhattan. But it might as well be a world away. In switching networks at a pivotal point in her career, Ms. Kelly, the No.   personality in cable television news, is taking a calculated risk that she can swap her dedicated Fox audience for the broader, but more fickle, viewership of network television. There are challenges from the  . Her splashy arrival has the potential to fray nerves among the big personalities at the network  ?   who already compete against one another for interviews and scoops. Ms. Kelly, 46, will also be taking on a daytime talk show format that has been a virtual graveyard for television news personalities in the last 10 years. And the new Sunday newsmagazine show that NBC plans to build around Ms. Kelly will go up against a giant that has not been meaningfully challenged for decades: ?60 Minutes? on CBS. Still, Ms. Kelly is a bona fide star with a   book and a breakout role in this year?s presidential campaign, when she clashed with Donald J. Trump. NBC News comes out the winner in one of the most closely watched talent sweepstakes in years, acquiring one of television?s biggest names who could play a role in any number of major network events, like coverage of elections or the Olympics. Interviews on Tuesday with network executives and producers  ?   from Fox, NBC and other rival channels  ?   suggest that Ms. Kelly?s performance at NBC will be as closely watched in the industry as her past few months of contract negotiations. Ms. Kelly will have to design her daytime talk show from scratch. Even though she made her name as a news anchor, she has argued that she is not obsessed with politics. When she hosted a   special on Fox in May  ?   her first major foray outside cable news  ?   she expressed a desire to combine the qualities of Oprah Winfrey, Barbara Walters and Charlie Rose. That special  ?   which featured interviews with Mr. Trump, the celebrity lawyer Robert Shapiro and the actress Laverne Cox  ?   received middling reviews. It was far from a ratings hit: Among adults younger than 50, the demographic most important to broadcasters, Ms. Kelly?s special performed about as well as ABC?s ?Beyond the Tank,? a   spinoff. A daily daytime talk show also poses risks.   talent like Jane Pauley, Meredith Vieira, Katie Couric and Anderson Cooper have taken a stab at the genre in the past, and each one failed. In Ms. Pauley?s case, NBC invested millions of dollars, but the show was yanked in 2005 after just one year. NBC said on Tuesday that Ms. Kelly?s show was expected to be closer to a news program than the typical daytime talk show, although it is unclear what exactly that will mean or how much appetite there is for news amid a landscape including shows like ?Days of Our Lives,? ?The Ellen DeGeneres Show? and ?Steve Harvey. ? The audience for daytime television is also significantly more diverse than Fox?s   viewership. Starting a Sunday rival to ?60 Minutes,? the   among newsmagazines, is likewise no easy task. ?Rock Center,? which Brian Williams hosted, lasted two seasons. NBC?s most recent newsmagazine, ?On Assignment,? ran    against ?60 Minutes? over five weeks the show averaged about four million viewers, compared with more than nine million for ?60 Minutes,? which broadcast two repeats during that time. (This season, ?60 Minutes? is averaging more than 14 million viewers.) It is also unclear how NBC will accommodate Ms. Kelly?s show during the National Football League season, when NBC?s popular ?Sunday Night Football? package includes a highly rated pregame show that begins at 7 p. m. Eastern. But Andrew Lack, NBC News?s chairman, has long had newsmagazines in his blood. In addition to overseeing a ?60 Minutes? competitor on CBS in the 1980s, Mr. Lack presided over NBC in the 1990s when newsmagazines, including the network?s popular ?Dateline,? dominated   lineups. Fox, meanwhile, must now set a course without one of its biggest names, as the network continues to recalibrate itself after the ouster of its chairman, Roger Ailes. Ms. Kelly?s exit from Fox News was so abrupt that it was announced on the day that the network had run a   ad in The Wall Street Journal trumpeting the ratings of its   lineup, with Ms. Kelly prominently pictured. Her departure stunned the Fox newsroom, where journalists and executives spent Tuesday afternoon speculating over which anchor might replace Ms. Kelly in the coveted 9 p. m. slot  ?   and wondering if Ms. Kelly would even appear that night. When Greta Van Susteren, another veteran anchor, announced her departure in September, network representatives visited her home to tell her not to bother coming in. In the end, Ms. Kelly was granted a chance to bid farewell to Fox News viewers  ?   her last show is Friday. It is not clear who will replace her. Fox News has never had an     lineup. Potential replacements being floated inside the network on Tuesday include four women who have regularly filled in for Ms. Kelly: Sandra Smith, a host of Fox?s noon show, ?Outnumbered? Trish Regan, a rising star at Fox Business Network Shannon Bream, who covers the Supreme Court and Martha MacCallum, a morning anchor. Kimberly Guilfoyle, a host of ?The Five? who is friendly with Mr. Trump?s circle, and Tucker Carlson, who has put up high ratings since taking over Fox News?s 7 p. m. slot, have also been suggested. Sean Hannity, whose viewership at 10 p. m. increased enormously in 2016 and has spiked since Election Day, could be moved up an hour, but his momentum in his time slot may make Fox executives reluctant to make a switch. One winner in the sweepstakes for Ms. Kelly could be CNN, even though it did not succeed in recruiting her. CNN, while still behind Fox News in total viewers by a wide margin, has occasionally beaten Fox among viewers 25 to 54, the demographic that determines advertising rates. In 2016, CNN finished within 58, 000 viewers of Fox in prime time in the demographic  ?   cutting Fox?s lead in half. Since the election, Fox has regained a sizable lead, but now, without spending a penny, CNN will now have an opportunity to take another run at Fox?s   advantage.\n",
      "A Coref: Megyn Kelly?s new office at NBC News sits a block north of Fox News headquarters in Midtown Manhattan. But Megyn Kelly?s new office at NBC News might as well be a world away. In switching networks at a pivotal point in Megyn Kelly?s's career, Megyn Kelly?s is taking a calculated risk that Megyn Kelly?s can swap Megyn Kelly?s's dedicated Fox News audience for the broader, but more fickle, viewership of network television. There are challenges from the  . Megyn Kelly?s's splashy arrival has the potential to fray nerves among the big personalities at NBC News  ?   who already compete against one another for interviews and scoops. Megyn Kelly?s will also be taking on a daytime talk show format that has been a virtual graveyard for television news personalities in the last 10 years. And the new Sunday newsmagazine show that NBC News plans to build around Megyn Kelly?s will go up against a giant that has not been meaningfully challenged for decades: ?60 Minutes? on CBS. Still, Megyn Kelly?s is a bona fide star with a   book and a breakout role in this year?s presidential campaign, when Megyn Kelly?s clashed with Donald J. Trump. NBC News comes out the winner in one of the most closely watched talent sweepstakes in years, acquiring Megyn Kelly?s. Interviews on Tuesday with network executives and producers  ?   from Fox News, NBC News and other rival channels  ?   suggest that Megyn Kelly?s performance at NBC News will be as closely watched in the industry as Megyn Kelly?s's past few months of contract negotiations. Megyn Kelly?s will have to design Megyn Kelly?s's daytime talk show from scratch. Even though Megyn Kelly?s made Megyn Kelly?s's name as a news anchor, Megyn Kelly?s has argued that Megyn Kelly?s is not obsessed with politics. When Megyn Kelly?s hosted a   special on Fox News in May  ?   Megyn Kelly?s's first major foray outside cable news  ?   Megyn Kelly?s expressed a desire to combine the qualities of Oprah Winfrey, Barbara Walters and Charlie Rose. That special  ?   which featured interviews with Donald J. Trump, the celebrity lawyer Robert Shapiro and the actress Laverne Cox  ?   received middling reviews. a   special was far from a ratings hit: Among adults younger than 50, the demographic most important to broadcasters, Megyn Kelly?s special performed about as well as ABC?s ?Beyond the Tank,? a   spinoff. A daily daytime talk show also poses risks.   talent like Jane Pauley, Meredith Vieira, Katie Couric and Anderson Cooper have taken a stab at the genre in the past, and each one failed. In Jane Pauley case, NBC News invested millions of dollars, but Jane Pauley was yanked in 2005 after just one year. NBC News said on Tuesday that Megyn Kelly?s show was expected to be closer to a news program than the typical daytime talk show, although it is unclear what exactly that will mean or how much appetite there is for news amid a landscape including shows like ?Days of Our Lives,? ?The Ellen DeGeneres Show? and ?Steve Harvey. ? The audience for daytime television is also significantly more diverse than Fox?s   viewership. Starting a Sunday rival to ?60 Minutes,? the   among newsmagazines, is likewise no easy task. ?Rock Center,? which Brian Williams hosted, lasted two seasons. NBC News most recent newsmagazine, ?On Assignment,? ran    against ?60 Minutes? over five weeks NBC?s most recent newsmagazine, ?On Assignment averaged about four million viewers, compared with more than nine million for ?60 Minutes,? which broadcast two repeats during five weeks. (This season, ?60 Minutes? is averaging more than 14 million viewers.) It is also unclear how NBC News will accommodate Megyn Kelly?s show during the National Football League season, when NBC News popular ?Sunday Night Football? package includes a highly rated pregame show that begins at 7 p. m. Eastern. But Andrew Lack, NBC News chairman, has long had newsmagazines in Andrew Lack, NBC News?s chairman,'s blood. In addition to overseeing a ?60 Minutes? competitor on CBS in the 1980s, Andrew Lack, NBC News?s chairman, presided over NBC News in the 1990s when newsmagazines, including NBC News popular ?Dateline,? dominated   lineups. Fox News, meanwhile, must now set a course without one of Fox News's biggest names, as Fox News continues to recalibrate Fox News after the ouster of Fox News's chairman, Roger Ailes. Megyn Kelly?s exit from Fox News was so abrupt that Ms. Kelly?s exit from Fox News was announced on the day that Fox News had run a   ad in The Wall Street Journal trumpeting the ratings of Fox News's   lineup, with Megyn Kelly?s prominently pictured. Megyn Kelly?s's departure stunned the Fox News newsroom, where journalists and executives spent Tuesday afternoon speculating over which anchor might replace Megyn Kelly?s in the coveted 9 p. m. slot  ?   and wondering if Megyn Kelly?s would even appear that night. When Greta Van Susteren, another veteran anchor, announced Greta Van Susteren, another veteran anchor,'s departure in September, network representatives visited Greta Van Susteren, another veteran anchor,'s home to tell Greta Van Susteren, another veteran anchor, not to bother coming in. In the end, Megyn Kelly?s was granted a chance to bid farewell to Fox News viewers  ?   Megyn Kelly?s's last show is Friday. It is not clear who will replace Megyn Kelly?s. Fox News has never had an     lineup. Potential replacements being floated inside Fox News on Tuesday include four women who have regularly filled in for Megyn Kelly?s: Sandra Smith, a host of Fox News noon show, ?Outnumbered? Trish Regan, a rising star at Fox Business Network Shannon Bream, who covers the Supreme Court and Martha MacCallum, a morning anchor. Kimberly Guilfoyle, a host of ?The Five? who is friendly with Donald J. Trump circle, and Tucker Carlson, who has put up high ratings since taking over Fox News 7 p. m. slot, have also been suggested. Sean Hannity, whose viewership at 10 p. m. increased enormously in 2016 and has spiked since Election Day, could be moved up an hour, but Sean Hannity, whose viewership at 10 p. m. increased enormously in 2016 and has spiked since Election Day,'s momentum in Sean Hannity, whose viewership at 10 p. m. increased enormously in 2016 and has spiked since Election Day,'s time slot may make Fox News executives reluctant to make a switch. One winner in the sweepstakes for Megyn Kelly?s could be CNN, even though CNN did not succeed in recruiting Megyn Kelly?s. CNN, while still behind Fox News in total viewers by a wide margin, has occasionally beaten Fox News among viewers 25 to 54, the demographic that determines advertising rates. In 2016, CNN finished within 58, 000 viewers of Fox News in prime time in viewers 25 to 54, the demographic that determines advertising rates  ?   cutting Fox News lead in half. Since the election, Fox News has regained a sizable lead, but now, without spending a penny, CNN will now have an opportunity to take another run at Fox?s lead.\n",
      "A Pre&Coref: megyn kelly new office nbc news sits block north fox news headquarters midtown manhattan . megyn kelly new office nbc news might well world away . switching network pivotal point megyn kelly 's career megyn kelly taking calculated risk megyn kelly swap megyn kelly 's dedicated fox news audience broader fickle viewership network television . challenge . megyn kelly 's splashy arrival potential fray nerve among big personality nbc news already compete one another interview scoop . megyn kelly also taking daytime talk show format virtual graveyard television news personality last 10 year . new sunday newsmagazine show nbc news plan build around megyn kelly go giant meaningfully challenged decade 60 minute cbs . still megyn kelly bona fide star book breakout role year presidential campaign megyn kelly clashed donald j. trump . nbc news come winner one closely watched talent sweepstakes year acquiring megyn kelly . interview tuesday network executive producer fox news nbc news rival channel suggest megyn kelly performance nbc news closely watched industry megyn kelly 's past month contract negotiation . megyn kelly design megyn kelly 's daytime talk show scratch . even though megyn kelly made megyn kelly 's name news anchor megyn kelly argued megyn kelly obsessed politics . megyn kelly hosted special fox news may megyn kelly 's first major foray outside cable news megyn kelly expressed desire combine quality oprah winfrey barbara walter charlie rose . special featured interview donald j. trump celebrity lawyer robert shapiro actress laverne cox received middling review . special far rating hit among adult younger 50 demographic important broadcaster megyn kelly special performed well abc beyond tank spinoff . daily daytime talk show also pose risk . talent like jane pauley meredith vieira katie couric anderson cooper taken stab genre past one failed . jane pauley case nbc news invested million dollar jane pauley yanked 2005 one year . nbc news said tuesday megyn kelly show expected closer news program typical daytime talk show although unclear exactly mean much appetite news amid landscape including show like day life ellen degeneres show steve harvey . audience daytime television also significantly diverse fox viewership . starting sunday rival 60 minute among newsmagazines likewise easy task . rock center brian williams hosted lasted two season . nbc news recent newsmagazine assignment ran 60 minute five week nbc recent newsmagazine assignment averaged four million viewer compared nine million 60 minute broadcast two repeat five week . season 60 minute averaging 14 million viewer . also unclear nbc news accommodate megyn kelly show national football league season nbc news popular sunday night football package includes highly rated pregame show begin 7 p. m. eastern . andrew lack nbc news chairman long newsmagazines andrew lack nbc news chairman 's blood . addition overseeing 60 minute competitor cbs 1980s andrew lack nbc news chairman presided nbc news 1990s newsmagazines including nbc news popular dateline dominated lineup . fox news meanwhile must set course without one fox news 's biggest name fox news continues recalibrate fox news ouster fox news 's chairman roger ailes . megyn kelly exit fox news abrupt ms. kelly exit fox news announced day fox news run ad wall street journal trumpeting rating fox news 's lineup megyn kelly prominently pictured . megyn kelly 's departure stunned fox news newsroom journalist executive spent tuesday afternoon speculating anchor might replace megyn kelly coveted 9 p. m. slot wondering megyn kelly would even appear night . greta van susteren another veteran anchor announced greta van susteren another veteran anchor 's departure september network representative visited greta van susteren another veteran anchor 's home tell greta van susteren another veteran anchor bother coming . end megyn kelly granted chance bid farewell fox news viewer megyn kelly 's last show friday . clear replace megyn kelly . fox news never lineup . potential replacement floated inside fox news tuesday include four woman regularly filled megyn kelly sandra smith host fox news noon show outnumbered trish regan rising star fox business network shannon bream cover supreme court martha maccallum morning anchor . kimberly guilfoyle host five friendly donald j. trump circle tucker carlson put high rating since taking fox news 7 p. m. slot also suggested . sean hannity whose viewership 10 p. m. increased enormously 2016 spiked since election day could moved hour sean hannity whose viewership 10 p. m. increased enormously 2016 spiked since election day 's momentum sean hannity whose viewership 10 p. m. increased enormously 2016 spiked since election day 's time slot may make fox news executive reluctant make switch . one winner sweepstakes megyn kelly could cnn even though cnn succeed recruiting megyn kelly . cnn still behind fox news total viewer wide margin occasionally beaten fox news among viewer 25 54 demographic determines advertising rate . 2016 cnn finished within 58 000 viewer fox news prime time viewer 25 54 demographic determines advertising rate cutting fox news lead half . since election fox news regained sizable lead without spending penny cnn opportunity take another run fox lead .\n"
     ]
    }
   ],
   "source": [
    "from fastcoref import spacy_component\n",
    "import spacy\n",
    "\n",
    "def coreference_resolution(context, model = 'fastcoref'):\n",
    "\t\n",
    "\tnlp = spacy.load('en_core_web_sm', exclude=[\"parser\", \"lemmatizer\", \"ner\", \"textcat\"])\n",
    "\t# setting\n",
    "\tif model == 'fastcoref':\n",
    "\t\tnlp.add_pipe(\n",
    "\t\t\t\"fastcoref\", \n",
    "\t\t\tconfig={\n",
    "\t\t\t\t\"enable_progress_bar\": False,\n",
    "\t\t\t\t}\n",
    "\t\t\t)\n",
    "\telif model == 'LingMessCoref':\n",
    "\t\tnlp.add_pipe(\n",
    "\t\t\t\"fastcoref\", \n",
    "\t\t\tconfig={\n",
    "\t\t\t\t\"enable_progress_bar\": False,\n",
    "\t\t\t\t'model_architecture': 'LingMessCoref', 'model_path': 'biu-nlp/lingmess-coref'\n",
    "\t\t\t\t}\n",
    "\t\t\t)\n",
    "\telse:\n",
    "\t\tprint(\"please select model fastcoref or LingMessCoref \")\n",
    "\t\t\n",
    "\tdoc = nlp(\n",
    "\t \tcontext, \n",
    "\t\tcomponent_cfg={\"fastcoref\": {'resolve_text': True}}\n",
    "\t\t)\n",
    "\treturn doc._.resolved_text\n",
    "\n",
    "coref_model = 'fastcoref'\n",
    "test_results = coreference_resolution(test_sentence, model = coref_model)\n",
    "print(\"Check the function coreference\")\n",
    "print(f\"Before: {test_sentence}\")\n",
    "print(f\"A Coref: {test_results}\")\n",
    "print(f\"A Pre&Coref: {preprocess_text(test_results)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f37af4de",
   "metadata": {},
   "source": [
    "### Text matching utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "69535660",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "sematic_model = {\n",
    "\t'Mpnet_cos': SentenceTransformer('multi-qa-mpnet-base-cos-v1'), # 420 MB\n",
    "\t'distilbert_cos': SentenceTransformer('multi-qa-distilbert-cos-v1'), # 250 MB\n",
    "\t'MiniLM_cos': SentenceTransformer('multi-qa-MiniLM-L6-cos-v1'), # 80 MB\n",
    "\t'Mpnet_dot': SentenceTransformer('multi-qa-mpnet-base-dot-v1'), # 420 MB\n",
    "\t'distilbert_dot': SentenceTransformer('multi-qa-distilbert-dot-v1'), # 250 MB\n",
    "\t'MiniLM_dot': SentenceTransformer('multi-qa-MiniLM-L6-dot-v1'), # 80 MB\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "870f1817",
   "metadata": {},
   "outputs": [],
   "source": [
    "reranker_model = {\n",
    "\t'MiniLM_L6': SentenceTransformer('msmarco-MiniLM-L6-cos-v5'), # 22.7M \n",
    "\t'distilbert': SentenceTransformer('msmarco-distilbert-cos-v5') # 66.4M\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c7ddcae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "match_model = sematic_model['MiniLM_cos']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "3266d361",
   "metadata": {},
   "outputs": [],
   "source": [
    "def semantic_similarity(sentence1, sentence2, model = sematic_model['Mpnet_cos']):\n",
    "\tembedding1 = model.encode(sentence1, convert_to_tensor=True)\n",
    "\tembedding2 = model.encode(sentence2, convert_to_tensor=True)\n",
    "\tcosine_scores = util.pytorch_cos_sim(embedding1, embedding2)\n",
    "\treturn cosine_scores.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "926f585a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_reranker(sentence1, sentence2, model = reranker_model['MiniLM_L6']):\n",
    "\tembedding1 = model.encode(sentence1, convert_to_tensor=True)\n",
    "\tembedding2 = model.encode(sentence2, convert_to_tensor=True)\n",
    "\tcosine_scores = util.pytorch_cos_sim(embedding1, embedding2)\n",
    "\treturn cosine_scores.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c640b9cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Mpnet_cos', 'distilbert_cos', 'MiniLM_cos', 'Mpnet_dot', 'distilbert_dot', 'MiniLM_dot'])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sematic_model.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e05c89ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 1/1 [00:00<00:00,  1.95it/s]\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00, 10.26it/s]\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00, 12.85it/s]\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00, 13.00it/s]\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00, 12.96it/s]\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00, 12.32it/s]\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00, 12.88it/s]\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00, 13.12it/s]\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00, 12.65it/s]\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00, 12.70it/s]\n",
      "Epoch: 100%|██████████| 10/10 [00:01<00:00,  8.00it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 384, 'do_lower_case': False}) with Transformer model: BertModel \n",
       "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
       "  (2): Normalize()\n",
       ")"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, InputExample, losses\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def fine_tune_model(DataSet, model):\n",
    "\t\n",
    "\ttrain_examples = []\n",
    "\tfor i in range(len(DataSet)):\n",
    "\t\texample = DataSet[i]\n",
    "\t\tfor j in range(3):\n",
    "\t\t\ttrain_examples.append(InputExample(texts=[example['query'], example['pos'][0], example['neg'][j]]))\n",
    "\t\n",
    " \t# Define your train dataset, the dataloader and the train loss\n",
    "\ttrain_dataloader = DataLoader(train_examples, shuffle=True, batch_size=32)\n",
    "\ttrain_loss = losses.TripletLoss(model)\n",
    " \n",
    "\t# Tune the model\n",
    "\tmodel.fit(train_objectives=[(train_dataloader, train_loss)], epochs=10)\n",
    "\treturn model\n",
    "\n",
    "DataSet = [\n",
    "\t{\n",
    "\t\t\"query\": \"President Trump, asked by an interviewer on Saturday why he respected President Vladimir V.\", \n",
    "\t\t\"pos\": [ \"president trump asked interviewer saturday president trump respected president vladimir v\" ], \n",
    "\t\t\"neg\": [\n",
    "\t\t\t\"putin russia\", \n",
    "\t\t\t\"putin russia even though president vladimir v\", \n",
    "\t\t\t\"interview broadcast sunday super bowl president trump asked president trump respected president vladimir v\"\n",
    "   \t\t\t]\n",
    "\t\t},\n",
    "\t{\n",
    "\t\t\"query\": \"Although North Korea has vowed to develop the ability to attack the United States with nuclear warheads and has tested missiles that can cover the Korean Peninsula and its vicinity, it has never tested a missile that could fly over the Pacific\", \n",
    "\t\t\"pos\": [ \"lthough north korea vowed develop ability attack united state nuclear warhead tested missile cover korean peninsula korean peninsula 's vicinity north korea never tested missile could fly pacific\" ], \n",
    "\t\t\"neg\": [\n",
    "\t\t\t\"two leader shared need firm action persuade north korea rethink north korea 's nuclear weapon development program vowed respond strongly north korea attempted military provocation mr\", \n",
    "\t\t\t\"new year day speech north korea leader said kim north korea leader 's country reached final stage preparing test intercontinental ballistic missile\", \n",
    "\t\t\t\"next day president trump said twitter post happen remains unclear close north korea building reliable intercontinental ballistic missile although north korea boasted successfully testing crucial technology past year engine heat shield missile\"\n",
    "   \t\t\t]\n",
    "\t\t},\n",
    "\t]\n",
    "\n",
    "model = reranker_model['MiniLM_L6']\n",
    "\n",
    "fine_tune_model(DataSet, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ab2302c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Answer\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
    "\n",
    "# Load the QA model and tokenizer\n",
    "model_name_qa = \"distilbert-base-cased-distilled-squad\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name_qa)\n",
    "model_qa = AutoModelForQuestionAnswering.from_pretrained(model_name_qa)\n",
    "\n",
    "def find_top_relevant_answer(question, predicted_sentence):\n",
    "\t\n",
    "\tinputs = tokenizer.encode_plus(question, predicted_sentence, return_tensors='pt', max_length=512, truncation_strategy='only_second')\n",
    "\tinput_ids = inputs['input_ids']\n",
    "\tattention_mask = inputs['attention_mask']\n",
    "\n",
    "\t# Pass the encoded input through the QA model\n",
    "\toutputs = model_qa(input_ids, attention_mask=attention_mask, return_dict=True)\n",
    "\tstart_logits = outputs.start_logits\n",
    "\tend_logits = outputs.end_logits\n",
    "\n",
    "\n",
    "\t# Decode the predicted start and end positions to get the answer\n",
    "\tstart_index = torch.argmax(start_logits)\n",
    "\tend_index = torch.argmax(end_logits) + 1\n",
    "\n",
    "\t# Skip over any tokens before the start position or after the end position\n",
    "\tfor j, token_id in enumerate(input_ids[0]):\n",
    "\t\tif j < start_index or j >= end_index:\n",
    "\t\t\tinput_ids[0][j] = tokenizer.pad_token_id\n",
    "\n",
    "\t# Decode the answer from the corresponding tokens\n",
    "\tanswer_tokens = input_ids[0][start_index:end_index]\n",
    "\tpredicted_answer = tokenizer.decode(answer_tokens)\n",
    "\t\n",
    "\treturn predicted_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "21f7dd7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Answer\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
    "\n",
    "# Load the QA model and tokenizer\n",
    "model_name_qa = \"distilbert-base-cased-distilled-squad\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name_qa)\n",
    "model_qa = AutoModelForQuestionAnswering.from_pretrained(model_name_qa)\n",
    "\n",
    "def find_top_relevant_answer(question, predicted_sentence):\n",
    "\t\n",
    "\tinputs = tokenizer.encode_plus(question, predicted_sentence, return_tensors='pt', max_length=512, truncation_strategy='only_second')\n",
    "\tinput_ids = inputs['input_ids']\n",
    "\tattention_mask = inputs['attention_mask']\n",
    "\n",
    "\t# Pass the encoded input through the QA model\n",
    "\toutputs = model_qa(input_ids, attention_mask=attention_mask, return_dict=True)\n",
    "\tstart_logits = outputs.start_logits\n",
    "\tend_logits = outputs.end_logits\n",
    "\n",
    "\n",
    "\t# Decode the predicted start and end positions to get the answer\n",
    "\tstart_index = torch.argmax(start_logits)\n",
    "\tend_index = torch.argmax(end_logits) + 1\n",
    "\n",
    "\t# Skip over any tokens before the start position or after the end position\n",
    "\tfor j, token_id in enumerate(input_ids[0]):\n",
    "\t\tif j < start_index or j >= end_index:\n",
    "\t\t\tinput_ids[0][j] = tokenizer.pad_token_id\n",
    "\n",
    "\t# Decode the answer from the corresponding tokens\n",
    "\tanswer_tokens = input_ids[0][start_index:end_index]\n",
    "\tpredicted_answer = tokenizer.decode(answer_tokens)\n",
    "\t\n",
    "\treturn predicted_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "34387456",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_top_relevant_sentences(question, article, match_model, top_n=1, min_confidence=0.5, c_stop = True, c_lower = True, c_lemma = True, coref_model = coref_model, split_type='spacy'):\n",
    "\t\n",
    "\t# Preprocess the question and article\n",
    "\tquestion_pre = preprocess_text(coreference_resolution(question, model = coref_model), c_stop = c_stop, c_lower = c_lower, c_lemma = c_lemma)\n",
    "\tarticle_pre = preprocess_text(coreference_resolution(article, model = coref_model), c_stop = c_stop, c_lower = c_lower, c_lemma = c_lemma)\n",
    "\t\n",
    "\t# Split the preprocessed article into sentences\n",
    "\tarticle_sentences = sentence_split(article_pre, split_type=split_type)\n",
    "\t\n",
    "\t# Initialize the list to hold top sentences with their similarity scores\n",
    "\ttop_sentences_with_scores = []\n",
    "\t\n",
    "\tif not article_sentences:\n",
    "\t\treturn [(\"No valid sentences found after processing.\", 0.0,\"\")]\n",
    "\t\t\n",
    "\tif match_model == 'CosineTfidf':\n",
    "\t\t# Create the vectorizer and transform the sentences to get their feature vectors\n",
    "\t\tvectorizer = TfidfVectorizer()\n",
    "\t\tvectorizer.fit([question_pre] + article_sentences)\n",
    "\t\tquestion_vec = vectorizer.transform([question_pre])\n",
    "\t\tsentences_vec = vectorizer.transform(article_sentences)\n",
    "\t\t# Calculate cosine similarity scores between the question and each sentence\n",
    "\t\tsimilarity_scores = cosine_similarity(question_vec, sentences_vec).flatten()\n",
    "  \n",
    "\t\t# Pair each sentence with its similarity score, filtering by minimum confidence\n",
    "\t\tfor score, sentence in zip(similarity_scores, article_sentences):\n",
    "\t\t\tif score >= min_confidence:\n",
    "\t\t\t\ttop_sentences_with_scores.append((\n",
    "\t\t\t\t\t\t\t\t\t\t\tsentence, \n",
    "\t\t\t\t\t\t\t\t\t\t\tround(score, 3), \n",
    "\t\t\t\t\t\t\t\t\t\t\tfind_top_relevant_answer(question_pre, sentence)\n",
    "\t\t\t\t\t\t\t\t\t\t\t))\n",
    "\t\n",
    "\telse: \n",
    "\t\t# Calculate similarity scores for each sentence\n",
    "\t\tfor sent in article_sentences:\n",
    "\t\t\tsimilarity_score = retrieve_reranker(question_pre,sent, match_model)\n",
    "\t\t\tif similarity_score >= min_confidence:\n",
    "\t\t\t\ttop_sentences_with_scores.append((\n",
    "\t\t\t\t\t\t\t\t\t\t\tsent, \n",
    "\t\t\t\t\t\t\t\t\t\t\tround(similarity_score, 3), \n",
    "\t\t\t\t\t\t\t\t\t\t\tfind_top_relevant_answer(question_pre, sent)\n",
    "\t\t\t\t\t\t\t\t\t\t\t))\n",
    "\t\n",
    "\t# Sort the sentences by similarity score in descending order\n",
    "\ttop_sentences_with_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "\t\n",
    "\t# Take only the top_n sentences\n",
    "\tif top_sentences_with_scores == []:\n",
    "\t\treturn [(\"no answer.\", 0.0,\"\")]\n",
    "\ttop_sentences_with_scores = top_sentences_with_scores[:top_n]\n",
    "\t\n",
    "\treturn top_sentences_with_scores if top_sentences_with_scores else [(\"No sentences meet the minimum confidence score.\", 0.0,\"\")]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ca2dedb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SEOUL, South Korea  ?   President Trump assured South Korea?s acting president on Monday of the United States? ?ironclad? commitment to defend the country, agreeing with Seoul to strengthen joint defense capabilities against North Korea. Mr. Trump?s assurances came amid anxiety in South Korea over the future of the alliance with the United States. During his campaign, Mr. Trump cast some doubt on the United States? defense and trade commitments, saying that South Korea was not paying enough to help keep 28, 500 American troops in the country. But speaking by phone to Hwang   the acting president of South Korea, Mr. Trump said that the coming visit to South Korea by Defense Secretary Jim Mattis reflected the close friendship of the two countries and the importance of their alliance. Mr. Mattis is scheduled to visit South Korea on Thursday on his first official trip abroad, which also includes a stop in Japan. ?President Trump reiterated our ironclad commitment to defend the R. O. K. including through the provision of extended deterrence, using the full range of military capabilities,? the White House said in a statement after Mr. Trump?s phone conversation with Mr. Hwang, using the initials for South Korea?s official name, the Republic of Korea. ?The two leaders agreed to take steps to strengthen joint defense capabilities to defend against the North Korean threat. ? Mr. Hwang?s office quoted Mr. Trump as saying that the United States would cooperate with South Korea ?100 percent? and that bilateral relations would be ?better than ever before. ? The two leaders shared the need for firm action to persuade North Korea to rethink its nuclear weapons development program and vowed to respond strongly if the North attempted military provocations, it said. Mr. Trump?s call with Mr. Hwang followed North Korea?s recent warnings that it could conduct its first test of an intercontinental ballistic missile ?anytime and anywhere,? in a rebuke to Mr. Trump. Although North Korea has vowed to develop the ability to attack the United States with nuclear warheads and has tested missiles that can cover the Korean Peninsula and its vicinity, it has never tested a   missile that could fly over the Pacific. In a New Year?s Day speech, Kim   North Korea?s leader, said his country had reached a ?final stage? in preparing to test an intercontinental ballistic missile. The next day Mr. Trump said in a Twitter post, ?It won?t happen!? It remains unclear how close North Korea is to building a reliable intercontinental ballistic missile, although North Korea has boasted of successfully testing crucial technology in the past year, such as   engines and heat shields for such a missile. Mr. Hwang, the prime minister of South Korea, is serving as acting president because President Park  ?s powers were suspended after the country?s Parliament voted to impeach her in December on charges of corruption and abuse of power. The Constitutional Court of South Korea is expected to decide in the coming weeks whether to formally end her presidency or reinstate her.'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df[df.index == 18128])['article'].iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd7c318",
   "metadata": {},
   "source": [
    "### User Interface"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49089ef",
   "metadata": {},
   "source": [
    "#### Positive case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "838d0b0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 239.94 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 49.01 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User -- input from article 17340: Who suggest that Ms. Kelly's performance at NBC will be as closely watched in the industry as her past few months of contract negotiations?\n",
      "System -- Answer with 0.729 confident score: fox news nbc news rival channel\n",
      "System -- Related Sentence: interview tuesday network executive producer fox news nbc news rival channel suggest megyn kelly performance nbc news closely watched industry megyn kelly 's past month contract negotiation .\n"
     ]
    }
   ],
   "source": [
    "questions = \"Who suggest that Ms. Kelly's performance at NBC will be as closely watched in the industry as her past few months of contract negotiations?\"\n",
    "id = 17340\n",
    "top_sentences_with_scores = find_top_relevant_sentences(questions, (df[df.index == id])['article'].iloc[0], reranker_model['MiniLM_L6'], top_n=1)\n",
    "predicted_sentence, confidence_score, predicted_answer = top_sentences_with_scores[0] if top_sentences_with_scores else (\"No answer found\", 0.0, \" \")\n",
    "print(f\"User -- input from article {id}: {questions}\")\n",
    "print(f\"System -- Answer with {confidence_score} confident score: {predicted_answer}\")\n",
    "print(f\"System -- Related Sentence: {predicted_sentence}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a50f0a24",
   "metadata": {},
   "source": [
    "#### Base cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "51ca8f38",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 219.25 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 37.49 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User -- input from article 17340: Whom asked by an interviewer on Saturday why he respected President Vladimir V. Putin of Russia even though he is a killer?\n",
      "System -- Answer with 0.0 confident score: \n",
      "System -- Sentence: no answer.\n"
     ]
    }
   ],
   "source": [
    "questions = 'Whom asked by an interviewer on Saturday why he respected President Vladimir V. Putin of Russia even though he is a killer?'\n",
    "id = 17340\n",
    "top_sentences_with_scores = find_top_relevant_sentences(questions, (df[df.index == id])['article'].iloc[0], reranker_model['MiniLM_L6'], top_n=1)\n",
    "predicted_sentence, confidence_score, predicted_answer = top_sentences_with_scores[0] if top_sentences_with_scores else (\"No answer found\", 0.0, \" \")\n",
    "print(f\"User -- input from article {id}: {questions}\")\n",
    "print(f\"System -- Answer with {confidence_score} confident score: {predicted_answer}\")\n",
    "print(f\"System -- Sentence: {predicted_sentence}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc17a32",
   "metadata": {},
   "source": [
    "### Test utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f8fcf7ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/13/2024 18:59:39 - INFO - \t Using default tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ROUGE1 & L: (0.536, 0.5)\n"
     ]
    }
   ],
   "source": [
    "from rouge_score import rouge_scorer\n",
    "\n",
    "def calculate_rouge_scores(reference, prediction):\n",
    "\tscorer = rouge_scorer.RougeScorer(['rouge1', 'rougeL'], use_stemmer=True)\n",
    "\tscores = scorer.score(reference.lower(), prediction.lower())\n",
    "\treturn round(scores['rouge1'].fmeasure,3), round(scores['rougeL'].fmeasure,3)\n",
    "\n",
    "ground_truth = \"NBC and other rival channels  ?   suggest that Ms. Kelly?s performance at NBC will be as closely watched in the industry as her past few months of contract negotiations\"\n",
    "pred = \"interview tuesday network executive producer fox news nbc news rival channel suggest megyn kelly performance nbc news closely watched industry megyn kelly 's past month contract negotiation\"\n",
    "\n",
    "print(f\" ROUGE1 & L: {calculate_rouge_scores(ground_truth, pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6651b491",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rouge_score import rouge_scorer\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def calculate_individual_metrics(predicted_sentence, gold_standard):\n",
    "\tscorer = rouge_scorer.RougeScorer(['rouge1', 'rougeL'], use_stemmer=True)\n",
    "\tscores = scorer.score(gold_standard.lower(), predicted_sentence.lower())\n",
    "\trouge1 = scores['rouge1'].fmeasure\n",
    "\trougeL = scores['rougeL'].fmeasure\n",
    "\t\n",
    "\t# Assuming binary presence of each word for F1 calculation\n",
    "\tpredicted = [1 if word in predicted_sentence.lower().split() else 0 for word in gold_standard.lower().split()]\n",
    "\tgold = [1 for _ in gold_standard.lower().split()]\n",
    "\tf1 = f1_score(gold, predicted, zero_division=1) if gold_standard else 0\n",
    "\t\n",
    "\treturn f1, rouge1, rougeL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8ca3eb",
   "metadata": {},
   "source": [
    "### Experimental Design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "063a10ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_sentence_with_metrics(article_ids, questions, gold_standards, df, match_model = match_model, top_n=10, min_confidence=0.1, c_stop = True, c_lower = True, c_lemma = True, coref_model = coref_model, split_type='spacy', model_qa = model_qa):\n",
    "\tresults = []\n",
    "\n",
    "\tfor article_id, question, gold_standard in zip(article_ids, questions, gold_standards):\n",
    "\t\tprocessed_article = str(df.loc[article_id, 'article'])\n",
    "\t\ttopic = str(df.loc[article_id, 'topic'])\n",
    "\t\ttop_sentences = find_top_relevant_sentences(question, processed_article, match_model, top_n = top_n , min_confidence = min_confidence, c_stop = c_stop, c_lower = c_lower, c_lemma = c_lemma, coref_model = coref_model, split_type=split_type)\n",
    "\t\tpredicted_sentence, confidence_score, predicted_answer = top_sentences[0] if top_sentences else (\"No answer found\", 0.0)\n",
    "\n",
    "\t\tf1, rouge1, rougeL = calculate_individual_metrics(predicted_answer, gold_standard)\n",
    "\t\t\n",
    "\t\tresults.append({\n",
    "\t\t\t'Article ID': article_id,\n",
    "\t\t\t'Topic': topic,\n",
    "\t\t\t'Question': question,\n",
    "\t\t\t'Gold Standard': gold_standard,\n",
    "\t\t\t'Predicted Sentence': predicted_sentence,\n",
    "\t\t\t'Predicted Answer': predicted_answer,\n",
    "\t\t\t'Confidence Score': confidence_score,\n",
    "\t\t\t'F1-Score': f1,\n",
    "\t\t\t'ROUGE-1': rouge1,\n",
    "\t\t\t'ROUGE-L': rougeL,\n",
    "\t\t})\n",
    "\n",
    "\tresults_df = pd.DataFrame(results)\n",
    "\t\n",
    "\treturn results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "159b8b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_articles_with_metrics(article_ids, questions, gold_standards, df, match_model = match_model, top_n=10, min_confidence=0.1, similarity_threshold=0.7, c_stop = True, c_lower = True, c_lemma = True, coref_model = coref_model, split_type='spacy'):\n",
    "\tevaluation_results = []\n",
    "\treciprocal_ranks = []\n",
    "\taverage_precisions = []\n",
    "\n",
    "\tfor article_id, question, gold_standard in zip(article_ids, questions, gold_standards):\n",
    "\t\tprocessed_article = (df[df.index == article_id])['article'].iloc[0]\n",
    "\t\ttopic = (df[df.index == article_id])['topic'].iloc[0]\n",
    "\t\t# top_sentences = find_top_relevant_sentences(question, processed_article, vectorizer, top_n=top_n, min_confidence=min_confidence)\n",
    "\t\ttop_sentences = find_top_relevant_sentences(question, processed_article, match_model, top_n = top_n , min_confidence = min_confidence, c_stop = c_stop, c_lower = c_lower, c_lemma = c_lemma, coref_model = coref_model, split_type=split_type)\n",
    "\t\t\n",
    "\t\ttop_matching_sentences = []\n",
    "\t\tfirst_relevant_rank = None\n",
    "\t\trelevant_hits = 0\n",
    "\t\tcumulative_precision = 0.0\n",
    "\t\thighest_similarity = 0\n",
    "\t\thighest_similarity_rank = None\n",
    "\t\thighest_similarity_sentence = \"\"\n",
    "\n",
    "\t\tfor idx, (sentence, score, answer_) in enumerate(top_sentences, start=1):\n",
    "\t\t\tsimilarity = semantic_similarity(sentence, gold_standard)\n",
    "\t\t\tif similarity > highest_similarity:\n",
    "\t\t\t\thighest_similarity = similarity\n",
    "\t\t\t\thighest_similarity_rank = idx\n",
    "\t\t\t\thighest_similarity_sentence = sentence\n",
    "\t\t\t\n",
    "\t\t\t# using the similarity_threshold to check with the ground truth without maunally\n",
    "\t\t\tif similarity >= similarity_threshold:\n",
    "\t\t\t\trelevant_hits += 1\n",
    "\t\t\t\tif first_relevant_rank is None:\n",
    "\t\t\t\t\tfirst_relevant_rank = idx\n",
    "\t\t\t\tprecision_at_this_rank = relevant_hits / idx\n",
    "\t\t\t\tcumulative_precision += precision_at_this_rank\n",
    "\t\t\t\n",
    "\t\t\ttop_matching_sentences.append({\n",
    "\t\t\t\t'Sentence': sentence,\n",
    "\t\t\t\t'Rank': idx,\n",
    "\t\t\t\t'Score': round(score, 2),\n",
    "\t\t\t\t'Similarity': round(similarity, 2)\n",
    "\t\t\t})\n",
    "\n",
    "\t\t# Calculate AP for the current question\n",
    "\t\tap = round(cumulative_precision / relevant_hits if relevant_hits > 0 else 0,2)\n",
    "\t\trr = round(1 / first_relevant_rank if first_relevant_rank else 0,2)\n",
    "\n",
    "\t\tevaluation_results.append({\n",
    "\t\t\t'Article ID': article_id,\n",
    "\t\t\t'Topic': topic,\n",
    "\t\t\t'Question': question,\n",
    "\t\t\t'Gold Standard': gold_standard,\n",
    "\t\t\t'Reciprocal Rank': rr,\n",
    "\t\t\t'Average Precision': ap,\n",
    "\t\t\t'Top Matching Sentences': top_matching_sentences,\n",
    "\t\t\t'Highest Similarity Rank': highest_similarity_rank,\n",
    "\t\t\t'Highest Similarity Sentence': highest_similarity_sentence\n",
    "\t\t})\n",
    "\n",
    "\t\treciprocal_ranks.append(rr)\n",
    "\t\taverage_precisions.append(ap)\n",
    "\n",
    "\t# Convert evaluation results to DataFrame\n",
    "\tresults_df = pd.DataFrame(evaluation_results)\n",
    "\tMRR = np.mean(reciprocal_ranks)\n",
    "\tMAP = np.mean(average_precisions)\n",
    "\n",
    "\treturn results_df, MRR, MAP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac614848",
   "metadata": {},
   "source": [
    "### DEV - finetune parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "bc15f5e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['MiniLM_L6', 'distilbert'])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reranker_model.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "4e44b66d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 48.74 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 33.40 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 220.17 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 37.60 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 70.25 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 39.19 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 163.29 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 42.69 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 158.63 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 33.75 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 110.60 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 36.11 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 74.85 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 37.44 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 184.24 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 33.64 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 220.36 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 52.89 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 201.73 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 36.75 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 271.53 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 70.15 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 272.62 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 79.74 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 224.13 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 49.06 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 128.62 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 48.77 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 270.84 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 48.44 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 72.89 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 38.12 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 69.89 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 44.29 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 204.03 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 31.23 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 257.60 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 36.46 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 179.90 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 39.56 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 219.94 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 46.32 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 234.53 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 34.02 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 202.48 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 48.04 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 275.00 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 76.33 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 256.16 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 38.20 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 294.71 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 40.64 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 241.08 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 41.05 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 227.24 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 43.81 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 217.57 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 40.21 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 139.98 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 69.85 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 244.79 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 80.61 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 128.90 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 56.71 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 217.40 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 73.88 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 251.26 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 36.31 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 194.97 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 40.62 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 175.74 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 27.06 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 184.06 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 38.29 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 256.74 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 39.15 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 288.19 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 49.93 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 212.18 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 51.42 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 113.03 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 48.74 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 106.35 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 44.29 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 240.80 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 45.67 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 46.88 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 40.64 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 198.13 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 41.34 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 80.59 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 40.22 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 235.13 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 37.99 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 95.51 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 43.25 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 169.89 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 49.55 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 181.66 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 43.11 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 271.95 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 49.12 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 313.17 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 52.85 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 234.91 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 74.32 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 156.47 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 70.99 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 219.31 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 76.75 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 152.32 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 33.77 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 150.11 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 32.06 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 204.58 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 35.88 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 88.79 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 29.66 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 217.15 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 37.44 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 104.81 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 31.29 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 311.22 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 43.46 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 152.46 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 113.17 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 289.52 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 80.44 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 286.38 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 96.70 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 69.67 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 91.82 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 107.34 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 36.44 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 217.52 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 38.95 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 165.78 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 50.46 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 239.06 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 48.39 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 108.83 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 20.57 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 188.20 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 49.17 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 137.25 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 85.94 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 176.25 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 53.46 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 290.02 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 93.38 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 143.43 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 90.24 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 246.30 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 108.88 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 281.36 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 103.11 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 282.16 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 102.77 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 216.16 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 98.17 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 216.40 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 27.75 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 159.65 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 25.00 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 195.66 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 37.57 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 255.61 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 16.10 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 33.77 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 23.98 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 123.93 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 24.24 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 293.84 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 28.58 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 272.04 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 69.48 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 309.89 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 53.57 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 174.70 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 41.85 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 282.10 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 78.03 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 228.46 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 65.95 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 183.72 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 65.49 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 119.69 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 28.77 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 229.84 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 27.99 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 190.68 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 51.60 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 226.24 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 53.63 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 197.55 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 47.83 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 181.32 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 49.34 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 240.79 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 37.94 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 260.02 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 40.62 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 243.32 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 47.60 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 101.09 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 47.04 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 245.45 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 37.59 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 198.22 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 36.16 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 181.45 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 38.00 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 171.35 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 38.17 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 173.13 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 44.56 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 175.58 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 62.47 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 190.11 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 75.10 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 207.13 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 42.64 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 280.26 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 75.65 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 156.67 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 50.37 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 260.68 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 49.12 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 270.55 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 31.00 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 115.83 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 45.60 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 190.73 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 17.23 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 227.28 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 40.65 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 199.41 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 27.47 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 197.78 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 34.82 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 148.79 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 37.42 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 201.75 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 32.34 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 200.72 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 51.80 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 110.16 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 58.99 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 255.36 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 34.04 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 179.69 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 36.89 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 238.73 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 38.35 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 158.16 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 35.82 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 160.77 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 38.30 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 230.14 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 69.62 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 201.33 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 64.91 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 228.67 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 40.25 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 163.48 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 72.42 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 215.02 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 31.44 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 208.93 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 34.47 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 14.02 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 27.97 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 149.06 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 28.61 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 285.31 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 39.16 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 112.83 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 41.67 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 155.01 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 49.71 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 156.54 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 39.40 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 175.60 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 40.81 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 176.77 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 48.54 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 163.29 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 36.30 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 211.07 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 26.51 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 213.81 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 27.88 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 219.69 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 30.05 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 227.28 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 42.79 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 190.62 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 36.48 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 205.38 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 32.17 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 179.38 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 49.74 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 243.08 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 37.12 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 214.54 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 43.31 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 120.32 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 71.00 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 154.66 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 72.99 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 209.08 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 36.01 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 123.52 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 36.69 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 235.46 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 13.84 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 203.37 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 36.21 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 58.75 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 33.80 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 181.82 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00,  8.62 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 217.15 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 35.94 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 101.59 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 96.49 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 176.25 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 115.39 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 293.16 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 113.98 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 185.02 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 94.69 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 231.42 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 54.82 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 183.15 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 42.63 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 237.87 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 46.65 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 160.54 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 48.21 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 167.67 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 47.32 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 234.70 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 27.73 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 151.58 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 50.72 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 218.01 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 95.09 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 197.58 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 93.90 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 215.25 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 71.40 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 141.70 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 94.84 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 257.94 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 91.42 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 168.41 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 102.26 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 64.50 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 93.54 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 165.45 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 33.73 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 220.71 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 30.30 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 129.35 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 37.93 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 222.27 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 34.24 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 217.39 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 32.03 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 231.96 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 18.95 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 99.07 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 31.88 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 209.03 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 67.34 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 257.68 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 74.17 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 306.85 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 74.44 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 245.34 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 74.27 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 250.75 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 77.62 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 139.16 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 75.16 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 194.14 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 31.39 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 111.41 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 18.67 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 218.24 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 49.43 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 233.59 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 52.87 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 119.66 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 53.58 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 196.38 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 47.77 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 147.47 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 34.41 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# Example usage with dataset\n",
    "nlp_model = spacy.load('en_core_web_sm')  # Make sure to add your coreference resolution pipe if needed\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "data = df_dev\n",
    "\n",
    "# Dummy questions and gold standards for illustration; replace with your actual data\n",
    "article_ids = (data.index.to_list())\n",
    "questions = data['questions'].to_list()\n",
    "gold_sentences = data['gold_sentences'].to_list()\n",
    "gold_standards = data['gold answer'].to_list()\n",
    "\n",
    "# Evaluate - setting parameter\n",
    "# match_model = sematic_model['MiniLM_cos'] # or CosineTfidf\n",
    "match_model = reranker_model['MiniLM_L6']\n",
    "# match_model = 'CosineTfidf'\n",
    "c_stop = False\n",
    "c_lower = True\n",
    "c_lemma = False\n",
    "split_type = 'textblob' # spacy or textblob or common\n",
    "coref_model = 'fastcoref' # fastcoref or LingMessCoref \n",
    "\n",
    "results_df_dev = evaluate_sentence_with_metrics(article_ids, questions, gold_standards, df, match_model = match_model, c_stop = c_stop, c_lower = c_lower, c_lemma = c_lemma, coref_model = coref_model, split_type=split_type)\n",
    "article_df_dev, MRR_dev, MAP_dev = evaluate_articles_with_metrics(article_ids, questions, gold_sentences, df, match_model = match_model, c_stop = c_stop, c_lower = c_lower, c_lemma = c_lemma, coref_model = coref_model, split_type=split_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "326e2485",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Article ID</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Question</th>\n",
       "      <th>Gold Standard</th>\n",
       "      <th>Predicted Sentence</th>\n",
       "      <th>Predicted Answer</th>\n",
       "      <th>Confidence Score</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>ROUGE-1</th>\n",
       "      <th>ROUGE-L</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17340</td>\n",
       "      <td>business</td>\n",
       "      <td>Where Megyn Kelly?s new office?</td>\n",
       "      <td>nbc news</td>\n",
       "      <td>megyn kelly s new office at nbc news sits a bl...</td>\n",
       "      <td>nbc news</td>\n",
       "      <td>0.828</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17623</td>\n",
       "      <td>business</td>\n",
       "      <td>What caused the shutdown of Laurel Canyon Boul...</td>\n",
       "      <td>Waterlogged porch collapse</td>\n",
       "      <td>the rain this week shut down laurel canyon bou...</td>\n",
       "      <td>the rain</td>\n",
       "      <td>0.713</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17623</td>\n",
       "      <td>business</td>\n",
       "      <td>How long did the drought in California last?</td>\n",
       "      <td>Six years</td>\n",
       "      <td>the arrival of another winter rain here a wet ...</td>\n",
       "      <td>six years</td>\n",
       "      <td>0.643</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17623</td>\n",
       "      <td>business</td>\n",
       "      <td>Whose concert marked a significant event in mu...</td>\n",
       "      <td>Johnny Cash's</td>\n",
       "      <td>the band actually performed twice in the morni...</td>\n",
       "      <td>the band actually performed twice in the morni...</td>\n",
       "      <td>0.480</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17559</td>\n",
       "      <td>business</td>\n",
       "      <td>Who responded to the claims in the opposition ...</td>\n",
       "      <td>Kellyanne Conway</td>\n",
       "      <td>one of memos generated by political operatives...</td>\n",
       "      <td>political operatives</td>\n",
       "      <td>0.670</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>17314</td>\n",
       "      <td>crime</td>\n",
       "      <td>What did  the gunman who killed at least 39 pe...</td>\n",
       "      <td>assault</td>\n",
       "      <td>the turkish authorities are still searching fo...</td>\n",
       "      <td>a police officer guarding an istanbul nightclub</td>\n",
       "      <td>0.583</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>17314</td>\n",
       "      <td>crime</td>\n",
       "      <td>Who is the government spokesman?</td>\n",
       "      <td>Numan Kurtulmus</td>\n",
       "      <td>the government s spokesman numan kurtulmus did...</td>\n",
       "      <td>numan kurtulmus</td>\n",
       "      <td>0.355</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>17314</td>\n",
       "      <td>crime</td>\n",
       "      <td>What happened in November?</td>\n",
       "      <td>a deadly car bombing</td>\n",
       "      <td>a rare exception came in november when the isl...</td>\n",
       "      <td>car bombing</td>\n",
       "      <td>0.325</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>17314</td>\n",
       "      <td>crime</td>\n",
       "      <td>How many The Turkish military said on Monday t...</td>\n",
       "      <td>at least 22 militants</td>\n",
       "      <td>the turkish military said on monday that the t...</td>\n",
       "      <td>at least 22</td>\n",
       "      <td>0.951</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>17559</td>\n",
       "      <td>business</td>\n",
       "      <td>Where did details of the reports about Russia ...</td>\n",
       "      <td>Washington</td>\n",
       "      <td>a summary of unsubstantiated reports that russ...</td>\n",
       "      <td>as an appendix to the intelligence agencies</td>\n",
       "      <td>0.678</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Article ID     Topic                                           Question  \\\n",
       "0        17340  business                    Where Megyn Kelly?s new office?   \n",
       "1        17623  business  What caused the shutdown of Laurel Canyon Boul...   \n",
       "2        17623  business       How long did the drought in California last?   \n",
       "3        17623  business  Whose concert marked a significant event in mu...   \n",
       "4        17559  business  Who responded to the claims in the opposition ...   \n",
       "..         ...       ...                                                ...   \n",
       "95       17314     crime  What did  the gunman who killed at least 39 pe...   \n",
       "96       17314     crime                   Who is the government spokesman?   \n",
       "97       17314     crime                         What happened in November?   \n",
       "98       17314     crime  How many The Turkish military said on Monday t...   \n",
       "99       17559  business  Where did details of the reports about Russia ...   \n",
       "\n",
       "                 Gold Standard  \\\n",
       "0                     nbc news   \n",
       "1   Waterlogged porch collapse   \n",
       "2                    Six years   \n",
       "3                Johnny Cash's   \n",
       "4             Kellyanne Conway   \n",
       "..                         ...   \n",
       "95                     assault   \n",
       "96             Numan Kurtulmus   \n",
       "97        a deadly car bombing   \n",
       "98       at least 22 militants   \n",
       "99                  Washington   \n",
       "\n",
       "                                   Predicted Sentence  \\\n",
       "0   megyn kelly s new office at nbc news sits a bl...   \n",
       "1   the rain this week shut down laurel canyon bou...   \n",
       "2   the arrival of another winter rain here a wet ...   \n",
       "3   the band actually performed twice in the morni...   \n",
       "4   one of memos generated by political operatives...   \n",
       "..                                                ...   \n",
       "95  the turkish authorities are still searching fo...   \n",
       "96  the government s spokesman numan kurtulmus did...   \n",
       "97  a rare exception came in november when the isl...   \n",
       "98  the turkish military said on monday that the t...   \n",
       "99  a summary of unsubstantiated reports that russ...   \n",
       "\n",
       "                                     Predicted Answer  Confidence Score  \\\n",
       "0                                            nbc news             0.828   \n",
       "1                                            the rain             0.713   \n",
       "2                                           six years             0.643   \n",
       "3   the band actually performed twice in the morni...             0.480   \n",
       "4                                political operatives             0.670   \n",
       "..                                                ...               ...   \n",
       "95    a police officer guarding an istanbul nightclub             0.583   \n",
       "96                                    numan kurtulmus             0.355   \n",
       "97                                        car bombing             0.325   \n",
       "98                                        at least 22             0.951   \n",
       "99        as an appendix to the intelligence agencies             0.678   \n",
       "\n",
       "    F1-Score   ROUGE-1   ROUGE-L  \n",
       "0   1.000000  1.000000  1.000000  \n",
       "1   0.000000  0.000000  0.000000  \n",
       "2   1.000000  1.000000  1.000000  \n",
       "3   0.000000  0.000000  0.000000  \n",
       "4   0.000000  0.000000  0.000000  \n",
       "..       ...       ...       ...  \n",
       "95  0.000000  0.000000  0.000000  \n",
       "96  1.000000  1.000000  1.000000  \n",
       "97  0.666667  0.666667  0.666667  \n",
       "98  0.857143  0.857143  0.857143  \n",
       "99  0.000000  0.000000  0.000000  \n",
       "\n",
       "[100 rows x 10 columns]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "8ed7cb8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary Article Metric Evaluation:\n",
      "MRR: 0.69\n",
      "MAP: 0.66\n",
      "Show the performance of sentence comparison\n",
      " AVG F1 score: 0.54, AVG ROUGE-1: 0.48, AVG ROUGE-L: 0.48\n",
      "Show the performance of information retrieval\n"
     ]
    }
   ],
   "source": [
    "# Evaluate\n",
    "# Print Summary\n",
    "print(\"Summary Article Metric Evaluation:\")\n",
    "print(f\"MRR: {MRR_dev:.2f}\")\n",
    "print(f\"MAP: {MAP_dev:.2f}\")\n",
    "\n",
    "print(\"Show the performance of sentence comparison\")\n",
    "print(\" AVG F1 score: {:.2f}, AVG ROUGE-1: {:.2f}, AVG ROUGE-L: {:.2f}\".format(\n",
    "\tnp.mean(results_df_dev['F1-Score']),\n",
    "\tnp.mean(results_df_dev['ROUGE-1']),\n",
    "\tnp.mean(results_df_dev['ROUGE-L'])))\n",
    "print(\"Show the performance of information retrieval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "54c9ea97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What caused the shutdown of Laurel Canyon Boulevard?\n",
      "Gold Standard Benchmark: The waterlogged porch of a house collapsed into the roadway, causing the shutdown of Laurel Canyon Boulevard\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Score</th>\n",
       "      <th>Similarity</th>\n",
       "      <th>Sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.80</td>\n",
       "      <td>the rain this week shut down laurel canyon boulevard after the waterlogged porch of a house collapsed into the roadway and flash flood warnings were issued in los angeles as storms swept back and forth across los angeles on thursday evening .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.51</td>\n",
       "      <td>mudslides closed interstate 80 as the storm passed through the sierra nevada .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.17</td>\n",
       "      <td>many years have started off wet and gone completely dry .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.31</td>\n",
       "      <td>in northern california storms produced extensive flooding in sonoma county and around sacramento among the parts of california .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.28</td>\n",
       "      <td>the arrival of another winter rain here a wet end to a week that began with heavy snows in the sierra nevada has begged a welcome question is the drought that punished california for six years over no question california has turned a corner .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.08</td>\n",
       "      <td>assembled in the heavily guarded dining room 2 the inmates couldn t get enough .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.27</td>\n",
       "      <td>reservoirs that were parched last year are close to capacity .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.02</td>\n",
       "      <td>it was on this day in 1968 that johnny cash played johnny cash at folsom prison concert .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.03</td>\n",
       "      <td>a year later johnny cash did another prison record at san quentin which was also successful .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.22</td>\n",
       "      <td>los angeles and on thursday it rained .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sentence_index = 1\n",
    "print(f\"Question: {article_df_dev['Question'][sentence_index]}\")\n",
    "print(f\"Gold Standard Benchmark: {article_df_dev['Gold Standard'][sentence_index]}\")\n",
    "check_results = pd.DataFrame(article_df_dev['Top Matching Sentences'][sentence_index])\n",
    "check_results = check_results.reindex(['Rank','Score','Similarity','Sentence'], axis=1)\n",
    "display_df(check_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f0d5fa",
   "metadata": {},
   "source": [
    "#### System Evaluation on 10 test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "12c2f807",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 32.18 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 37.51 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 26.50 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 69.81 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 173.01 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 35.68 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 227.47 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 30.76 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 207.60 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 13.90 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 172.26 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 63.14 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 258.40 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 57.21 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 136.52 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 38.38 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 83.10 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 53.38 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 139.06 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 78.35 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 175.91 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 32.08 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 116.71 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 24.54 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 91.03 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 20.09 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 128.93 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 34.73 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 205.55 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 21.23 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 94.88 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 52.38 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 253.92 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 64.76 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 195.19 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 44.30 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 134.83 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 53.98 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 37.68 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 81.73 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary Article Metric Evaluation:\n",
      "MRR: 1.00\n",
      "MAP: 0.96\n",
      "Show the performance of sentence comparison\n",
      " AVG F1 score: 0.71, AVG ROUGE-1: 0.69, AVG ROUGE-L: 0.69\n",
      "Show the performance of information retrieval\n"
     ]
    }
   ],
   "source": [
    "# Example usage with dataset\n",
    "nlp_model = spacy.load('en_core_web_sm')  # Make sure to add your coreference resolution pipe if needed\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Dummy questions and gold standards for illustration; replace with your actual data\n",
    "article_ids = [\n",
    "\t17340, \n",
    "\t18303,\n",
    "\t17654,\n",
    "\t17726,\n",
    "\t17285,\n",
    "\t17999,\n",
    "\t17306,\n",
    "\t17312,\n",
    "\t17952,\n",
    "\t18128\n",
    "\t]\n",
    "questions = [\n",
    "\t\"Who suggest that Ms. Kelly's performance at NBC will be as closely watched in the industry as her past few months of contract negotiations?\", \n",
    "\t'Whom asked by an interviewer on Saturday why he respected President Vladimir V. Putin of Russia even though he is a killer?',\n",
    "\t\"Who wrote the novel The Exorcist was both a milestone in horror fiction and a turning point in his own career?\",\n",
    "\t\"what is the topic the American Museum of Natural History has long been on the front lines for discussion?\",\n",
    "\t\"When Walt Disneys Bambi opened, which critics praised its spare, haunting visual style, vastly different from anything Disney had done before?\",\n",
    "\t\"When the group of scientists who orchestrate the Doomsday Clock moved its minute hand from three to two and a half minutes before the final hour?\",\n",
    "\t\"What Mariah Carey suffered through a performance train wreck in Times Square on New Year?s Eve?\", \n",
    "\t\"What happened at an Istanbul nightclub on New Year's Day?\",\n",
    "\t\"Where the turbines would be connected to a substation?\",\n",
    "\t\"which country has vowed to develop the ability to attack the United States with nuclear warheads?\"\n",
    "\t]\n",
    "gold_sentences = [\n",
    "\t\"Interviews on Tuesday with network executives and producers from Fox, NBC and other rival channels suggest that Ms. Kelly?s performance at NBC will be as closely watched in the industry as her past few months of contract negotiations.\", \n",
    "\t\"President Trump, asked by an interviewer on Saturday why he respected President Vladimir V. Putin of Russia even though he is a killer, seemed to equate Mr. Putin?s actions with those of the United States.\",\n",
    "\t'William Peter Blatty, the author whose book The Exorcist was both a milestone in horror fiction and a turning point in his own career.',\n",
    "\t\"The American Museum of Natural History has long been on the front lines of the climate change discussion, as its scientists study the potential damage and its educators try to alert new generations to the dangers of global warming.\",\n",
    "\t\"When Walt Disney?s ?Bambi? opened in 1942, critics praised its spare, haunting visual style, vastly different from anything Disney had done before.\",\n",
    "\t\"On Thursday, the group of scientists who orchestrate the Doomsday Clock, a symbolic instrument informing the public when the earth is facing imminent disaster, moved its minute hand from three to two and a half minutes before the final hour.\",\n",
    "\t\"Mariah Carey suffered through a performance train wreck in Times Square on New Year?s Eve as malfunctions left her at a loss vocally during her hit song Emotions,struggling to reach notes and to sync the lyrics and music.\",\n",
    "\t\"The Turkish authorities are hunting for the gunman who opened fire at an Istanbul nightclub on New Year's Day, killing at least 39 people from no fewer than 12 countries.\",\n",
    "\t\"The turbines, each roughly 600 feet tall, would be connected to a substation in East Hampton by a undersea cable.\",\n",
    "\t\"North Korea has vowed to develop the ability to attack the United States with nuclear warheads and has tested missiles that can cover the Korean Peninsula and its vicinity, it has never tested a   missile that could fly over the Pacific.\"\n",
    "\t]\n",
    "gold_standards = [\n",
    "\t\"Fox, NBC and other rival channels\", \n",
    "\t\"President Trump.\",\n",
    "\t'William Peter Blatty',\n",
    "\t\"climate change\",\n",
    "\t\"1942\",\n",
    "\t\"Thursday\",\n",
    "\t\"suffered through a performance train wreck\",\n",
    "\t\"gunman opened fire\",\n",
    "\t\"East Hampton by a undersea cable.\",\n",
    "\t\"North Korea\"\n",
    "\t]\n",
    "\n",
    "# Evaluate - setting parameter\n",
    "match_model = sematic_model['distilbert_cos'] # or CosineTfidf\n",
    "c_stop = False\n",
    "c_lower = True\n",
    "c_lemma = False\n",
    "split_type = 'textblob' # spacy or textblob or common\n",
    "coref_model = 'fastcoref' # fastcoref or LingMessCoref \n",
    "\n",
    "results_df_dev = evaluate_sentence_with_metrics(article_ids, questions, gold_standards, df, match_model = match_model, c_stop = c_stop, c_lower = c_lower, c_lemma = c_lemma, coref_model = coref_model, split_type=split_type)\n",
    "article_df_dev, MRR, MAP = evaluate_articles_with_metrics(article_ids, questions, gold_sentences, df, match_model = match_model, c_stop = c_stop, c_lower = c_lower, c_lemma = c_lemma, coref_model = coref_model, split_type=split_type)\n",
    "# Evaluate\n",
    "# Print Summary\n",
    "print(\"Summary Article Metric Evaluation:\")\n",
    "print(f\"MRR: {MRR:.2f}\")\n",
    "print(f\"MAP: {MAP:.2f}\")\n",
    "\n",
    "print(\"Show the performance of sentence comparison\")\n",
    "print(\" AVG F1 score: {:.2f}, AVG ROUGE-1: {:.2f}, AVG ROUGE-L: {:.2f}\".format(\n",
    "\tnp.mean(results_df_dev['F1-Score']),\n",
    "\tnp.mean(results_df_dev['ROUGE-1']),\n",
    "\tnp.mean(results_df_dev['ROUGE-L'])))\n",
    "print(\"Show the performance of information retrieval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "f5bb7efe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Article ID</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Question</th>\n",
       "      <th>Gold Standard</th>\n",
       "      <th>Predicted Sentence</th>\n",
       "      <th>Predicted Answer</th>\n",
       "      <th>Confidence Score</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>ROUGE-1</th>\n",
       "      <th>ROUGE-L</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17340</td>\n",
       "      <td>business</td>\n",
       "      <td>Who suggest that Ms. Kelly's performance at NB...</td>\n",
       "      <td>Fox, NBC and other rival channels</td>\n",
       "      <td>interviews on tuesday with network executives ...</td>\n",
       "      <td>network executives and producers from fox news...</td>\n",
       "      <td>0.823</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.631579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18303</td>\n",
       "      <td>business</td>\n",
       "      <td>Whom asked by an interviewer on Saturday why h...</td>\n",
       "      <td>President Trump.</td>\n",
       "      <td>president trump asked by an interviewer on sat...</td>\n",
       "      <td>president trump</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17654</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>Who wrote the novel The Exorcist was both a mi...</td>\n",
       "      <td>William Peter Blatty</td>\n",
       "      <td>william peter blatty the author whose book the...</td>\n",
       "      <td>william peter blatty</td>\n",
       "      <td>0.705</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17726</td>\n",
       "      <td>business</td>\n",
       "      <td>what is the topic the American Museum of Natur...</td>\n",
       "      <td>climate change</td>\n",
       "      <td>the american museum of natural history has lon...</td>\n",
       "      <td>climate change discussion</td>\n",
       "      <td>0.782</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17285</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>When Walt Disneys Bambi opened, which critics ...</td>\n",
       "      <td>1942</td>\n",
       "      <td>when walt disney s bambi opened in 1942 critic...</td>\n",
       "      <td>1942</td>\n",
       "      <td>0.920</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>17999</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>When the group of scientists who orchestrate t...</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>on thursday the group of scientists who orches...</td>\n",
       "      <td>thursday</td>\n",
       "      <td>0.784</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>17306</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>What Mariah Carey suffered through a performan...</td>\n",
       "      <td>suffered through a performance train wreck</td>\n",
       "      <td>mariah carey suffered through a performance tr...</td>\n",
       "      <td></td>\n",
       "      <td>0.851</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>17312</td>\n",
       "      <td>politics</td>\n",
       "      <td>What happened at an Istanbul nightclub on New ...</td>\n",
       "      <td>gunman opened fire</td>\n",
       "      <td>here s what you need to know the turkish autho...</td>\n",
       "      <td></td>\n",
       "      <td>0.702</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>17952</td>\n",
       "      <td>politics</td>\n",
       "      <td>Where the turbines would be connected to a sub...</td>\n",
       "      <td>East Hampton by a undersea cable.</td>\n",
       "      <td>the turbines each roughly 600 feet tall would ...</td>\n",
       "      <td>east hampton</td>\n",
       "      <td>0.732</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>18128</td>\n",
       "      <td>politics</td>\n",
       "      <td>which country has vowed to develop the ability...</td>\n",
       "      <td>North Korea</td>\n",
       "      <td>although north korea has vowed to develop the ...</td>\n",
       "      <td>north korea</td>\n",
       "      <td>0.582</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Article ID          Topic  \\\n",
       "0       17340       business   \n",
       "1       18303       business   \n",
       "2       17654  entertainment   \n",
       "3       17726       business   \n",
       "4       17285  entertainment   \n",
       "5       17999  entertainment   \n",
       "6       17306  entertainment   \n",
       "7       17312       politics   \n",
       "8       17952       politics   \n",
       "9       18128       politics   \n",
       "\n",
       "                                            Question  \\\n",
       "0  Who suggest that Ms. Kelly's performance at NB...   \n",
       "1  Whom asked by an interviewer on Saturday why h...   \n",
       "2  Who wrote the novel The Exorcist was both a mi...   \n",
       "3  what is the topic the American Museum of Natur...   \n",
       "4  When Walt Disneys Bambi opened, which critics ...   \n",
       "5  When the group of scientists who orchestrate t...   \n",
       "6  What Mariah Carey suffered through a performan...   \n",
       "7  What happened at an Istanbul nightclub on New ...   \n",
       "8  Where the turbines would be connected to a sub...   \n",
       "9  which country has vowed to develop the ability...   \n",
       "\n",
       "                                Gold Standard  \\\n",
       "0           Fox, NBC and other rival channels   \n",
       "1                            President Trump.   \n",
       "2                        William Peter Blatty   \n",
       "3                              climate change   \n",
       "4                                        1942   \n",
       "5                                    Thursday   \n",
       "6  suffered through a performance train wreck   \n",
       "7                          gunman opened fire   \n",
       "8           East Hampton by a undersea cable.   \n",
       "9                                 North Korea   \n",
       "\n",
       "                                  Predicted Sentence  \\\n",
       "0  interviews on tuesday with network executives ...   \n",
       "1  president trump asked by an interviewer on sat...   \n",
       "2  william peter blatty the author whose book the...   \n",
       "3  the american museum of natural history has lon...   \n",
       "4  when walt disney s bambi opened in 1942 critic...   \n",
       "5  on thursday the group of scientists who orches...   \n",
       "6  mariah carey suffered through a performance tr...   \n",
       "7  here s what you need to know the turkish autho...   \n",
       "8  the turbines each roughly 600 feet tall would ...   \n",
       "9  although north korea has vowed to develop the ...   \n",
       "\n",
       "                                    Predicted Answer  Confidence Score  \\\n",
       "0  network executives and producers from fox news...             0.823   \n",
       "1                                    president trump             0.875   \n",
       "2                               william peter blatty             0.705   \n",
       "3                          climate change discussion             0.782   \n",
       "4                                               1942             0.920   \n",
       "5                                           thursday             0.784   \n",
       "6                                                                0.851   \n",
       "7                                                                0.702   \n",
       "8                                       east hampton             0.732   \n",
       "9                                        north korea             0.582   \n",
       "\n",
       "   F1-Score   ROUGE-1   ROUGE-L  \n",
       "0  0.909091  0.631579  0.631579  \n",
       "1  0.666667  1.000000  1.000000  \n",
       "2  1.000000  1.000000  1.000000  \n",
       "3  1.000000  0.800000  0.800000  \n",
       "4  1.000000  1.000000  1.000000  \n",
       "5  1.000000  1.000000  1.000000  \n",
       "6  0.000000  0.000000  0.000000  \n",
       "7  0.000000  0.000000  0.000000  \n",
       "8  0.500000  0.500000  0.500000  \n",
       "9  1.000000  1.000000  1.000000  "
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "dedb68b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 0 semantic similarity score: 0.67\n",
      "Question: Who suggest that Ms. Kelly's performance at NBC will be as closely watched in the industry as her past few months of contract negotiations?\n",
      "Gold Sentence: Interviews on Tuesday with network executives and producers from Fox, NBC and other rival channels suggest that Ms. Kelly?s performance at NBC will be as closely watched in the industry as her past few months of contract negotiations.\n",
      "Related Sentence: interviews on tuesday with network executives and producers from fox news nbc news and other rival channels suggest that megyn kelly s performance at nbc news will be as closely watched in the industry as megyn kelly s 's past few months of contract negotiations .\n",
      "Gold Standard: Fox, NBC and other rival channels\n",
      "Predicted Sentence: network executives and producers from fox news nbc news and other rival channels\n",
      "---------------------------\n",
      "Query 1 semantic similarity score: 0.81\n",
      "Question: Whom asked by an interviewer on Saturday why he respected President Vladimir V. Putin of Russia even though he is a killer?\n",
      "Gold Sentence: President Trump, asked by an interviewer on Saturday why he respected President Vladimir V. Putin of Russia even though he is a killer, seemed to equate Mr. Putin?s actions with those of the United States.\n",
      "Related Sentence: president trump asked by an interviewer on saturday why president trump respected president vladimir v. putin of russia even though president vladimir v. putin of russia is a killer seemed to equate president vladimir v. putin of russia actions with those of the united states .\n",
      "Gold Standard: President Trump.\n",
      "Predicted Sentence: president trump\n",
      "---------------------------\n",
      "Query 2 semantic similarity score: 1.0\n",
      "Question: Who wrote the novel The Exorcist was both a milestone in horror fiction and a turning point in his own career?\n",
      "Gold Sentence: William Peter Blatty, the author whose book The Exorcist was both a milestone in horror fiction and a turning point in his own career.\n",
      "Related Sentence: william peter blatty the author whose book the exorcist was both a milestone in horror fiction and a turning point in mr. blatty who wrote the screenplay 's own career died on thursday in bethesda md .\n",
      "Gold Standard: William Peter Blatty\n",
      "Predicted Sentence: william peter blatty\n",
      "---------------------------\n",
      "Query 3 semantic similarity score: 0.8\n",
      "Question: what is the topic the American Museum of Natural History has long been on the front lines for discussion?\n",
      "Gold Sentence: The American Museum of Natural History has long been on the front lines of the climate change discussion, as its scientists study the potential damage and its educators try to alert new generations to the dangers of global warming.\n",
      "Related Sentence: the american museum of natural history has long been on the front lines of the climate change discussion as the american museum of natural history 's scientists study the potential damage and the american museum of natural history 's educators that mission to alert new generations to the dangers of global warming .\n",
      "Gold Standard: climate change\n",
      "Predicted Sentence: climate change discussion\n",
      "---------------------------\n",
      "Query 4 semantic similarity score: 1.0\n",
      "Question: When Walt Disneys Bambi opened, which critics praised its spare, haunting visual style, vastly different from anything Disney had done before?\n",
      "Gold Sentence: When Walt Disney?s ?Bambi? opened in 1942, critics praised its spare, haunting visual style, vastly different from anything Disney had done before.\n",
      "Related Sentence: when walt disney s bambi opened in 1942 critics praised walt disney s bambi 's spare haunting visual style vastly different from anything walt disney s had done before .\n",
      "Gold Standard: 1942\n",
      "Predicted Sentence: 1942\n",
      "---------------------------\n",
      "Query 5 semantic similarity score: 1.0\n",
      "Question: When the group of scientists who orchestrate the Doomsday Clock moved its minute hand from three to two and a half minutes before the final hour?\n",
      "Gold Sentence: On Thursday, the group of scientists who orchestrate the Doomsday Clock, a symbolic instrument informing the public when the earth is facing imminent disaster, moved its minute hand from three to two and a half minutes before the final hour.\n",
      "Related Sentence: on thursday the group of scientists who orchestrate the doomsday clock a symbolic instrument informing the public when the earth is facing imminent disaster moved the doomsday clock a symbolic instrument informing the public when the earth is facing imminent disaster 's minute hand from three to two and a half minutes before the final hour .\n",
      "Gold Standard: Thursday\n",
      "Predicted Sentence: thursday\n",
      "---------------------------\n",
      "Query 6 semantic similarity score: -0.0\n",
      "Question: What Mariah Carey suffered through a performance train wreck in Times Square on New Year?s Eve?\n",
      "Gold Sentence: Mariah Carey suffered through a performance train wreck in Times Square on New Year?s Eve as malfunctions left her at a loss vocally during her hit song Emotions,struggling to reach notes and to sync the lyrics and music.\n",
      "Related Sentence: mariah carey suffered through a performance train wreck in times square on new year s eve as malfunctions left mariah carey at a loss vocally during mariah carey 's hit song emotions the trouble to reach notes and to sync the lyrics and music .\n",
      "Gold Standard: suffered through a performance train wreck\n",
      "Predicted Sentence: \n",
      "---------------------------\n",
      "Query 7 semantic similarity score: 0.06\n",
      "Question: What happened at an Istanbul nightclub on New Year's Day?\n",
      "Gold Sentence: The Turkish authorities are hunting for the gunman who opened fire at an Istanbul nightclub on New Year's Day, killing at least 39 people from no fewer than 12 countries.\n",
      "Related Sentence: here s what you need to know the turkish authorities are hunting for the gunman who opened fire at an istanbul nightclub on new year s day killing at least 39 people from no fewer than 12 countries .\n",
      "Gold Standard: gunman opened fire\n",
      "Predicted Sentence: \n",
      "---------------------------\n",
      "Query 8 semantic similarity score: 0.52\n",
      "Question: Where the turbines would be connected to a substation?\n",
      "Gold Sentence: The turbines, each roughly 600 feet tall, would be connected to a substation in East Hampton by a undersea cable.\n",
      "Related Sentence: the turbines each roughly 600 feet tall would be connected to a substation in east hampton by a undersea cable .\n",
      "Gold Standard: East Hampton by a undersea cable.\n",
      "Predicted Sentence: east hampton\n",
      "---------------------------\n",
      "Query 9 semantic similarity score: 1.0\n",
      "Question: which country has vowed to develop the ability to attack the United States with nuclear warheads?\n",
      "Gold Sentence: North Korea has vowed to develop the ability to attack the United States with nuclear warheads and has tested missiles that can cover the Korean Peninsula and its vicinity, it has never tested a   missile that could fly over the Pacific.\n",
      "Related Sentence: although north korea has vowed to develop the ability to attack the united states with nuclear warheads and has tested missiles that can cover the korean peninsula and the korean peninsula 's vicinity north korea has never tested a missile that could fly over the pacific .\n",
      "Gold Standard: North Korea\n",
      "Predicted Sentence: north korea\n",
      "---------------------------\n"
     ]
    }
   ],
   "source": [
    "results_df[['Gold Standard','Predicted Sentence']]\n",
    "for i in range(len(results_df)):\n",
    "\tprint(f\"Query {i} semantic similarity score: {round(semantic_similarity(results_df['Gold Standard'][i], results_df['Predicted Answer'][i]),2)}\")\n",
    "\tprint(f\"Question: \" + results_df['Question'][i])\n",
    "\tprint(f\"Gold Sentence: \" + gold_sentences[i])\n",
    "\tprint(f\"Related Sentence: \" + results_df['Predicted Sentence'][i])\n",
    "\tprint(f\"Gold Standard: \" + results_df['Gold Standard'][i])\n",
    "\tprint(f\"Predicted Sentence: \" + results_df['Predicted Answer'][i])\n",
    "\tprint(\"---------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "e6564c70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What happened at an Istanbul nightclub on New Year's Day?\n",
      "Gold Standard Benchmark: The Turkish authorities are hunting for the gunman who opened fire at an Istanbul nightclub on New Year's Day, killing at least 39 people from no fewer than 12 countries.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Score</th>\n",
       "      <th>Similarity</th>\n",
       "      <th>Sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.97</td>\n",
       "      <td>here s what you need to know the turkish authorities are hunting for the gunman who opened fire at an istanbul nightclub on new year s day killing at least 39 people from no fewer than 12 countries .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.86</td>\n",
       "      <td>the islamic state claimed the gunman who opened fire at an istanbul nightclub on new year s day killing at least 39 people from no fewer than 12 countries as a hero soldier of the caliphate and appeared to refer to turkey s role in the syrian war .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.38</td>\n",
       "      <td>the new york times suicide bombers struck the international airport in mogadishu somalia killing at least three security officers .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.09</td>\n",
       "      <td>good morning .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.18</td>\n",
       "      <td>fans around the world plan to toast the professor at 9 p. m. local time .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.28</td>\n",
       "      <td>most major markets reopen after new year s holiday .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.40</td>\n",
       "      <td>in iraq the islamic state claimed a suicide bombing in central baghdad that killed dozens even as the islamic state makes a brutal effort to hang on to the islamic state 's only remaining iraqi stronghold mosul .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.13</td>\n",
       "      <td>tyrus wong who endured racial bias to become one of the most celebrated artists of the 20th century and whose influence was crucial to the animated film bambi died at 106. finally our asia correspondents don t limit our asia correspondents to traditional news stories .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.34</td>\n",
       "      <td>al jazeera a prison battle in brazil between gangs fighting for control of the cocaine trade left about 60 inmates dead some decapitated .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.13</td>\n",
       "      <td>enjoy .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sentence_index = 7\n",
    "print(f\"Question: {article_df_dev['Question'][sentence_index]}\")\n",
    "print(f\"Gold Standard Benchmark: {article_df_dev['Gold Standard'][sentence_index]}\")\n",
    "check_results = pd.DataFrame(article_df_dev['Top Matching Sentences'][sentence_index])\n",
    "check_results = check_results.reindex(['Rank','Score','Similarity','Sentence'], axis=1)\n",
    "display_df(check_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3a91b4",
   "metadata": {},
   "source": [
    "## B. References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab04abe",
   "metadata": {},
   "source": [
    "[1] Preprocessing - NLTK: https://www.nltk.org/\n",
    "\n",
    "[2] Preprocessing - spaCy: https://spacy.io/usage/spacy-101\n",
    "\n",
    "[3] Sentence splitting: https://towardsdatascience.com/building-a-question-answering-system-part-1-9388aadff507\n",
    "\n",
    "[4] Model distilbert: https://huggingface.co/distilbert/distilbert-base-cased\n",
    "\n",
    "[5] Transfermer: https://huggingface.co/transformers/v3.0.2/model_doc/auto.html\n",
    "\n",
    "[6] Pretrained model + traineig method: https://www.sbert.net/docs/pretrained_models.html\n",
    "\n",
    "[7] Fine-tuned model: https://huggingface.co/blog/how-to-train-sentence-transformers\n",
    "\n",
    "** all the related theory provided the reference on report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf7553c1",
   "metadata": {},
   "source": [
    "## C. Appendix"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
